{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_4_Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3i0W-wSauZ7"
      },
      "source": [
        "Spring 2021\n",
        "<img src=\"https://www.cuipcairo.org/sites/default/files/styles/medium/public/49658177_2020840098011471_2893445443553853440_n.png?itok=672tzxcF\"\n",
        " width=\"80px\" align=\"right\">\n",
        "\n",
        "CIE 555, Neural Networks and Deep Learning\n",
        "\n",
        "University of Science and Technology, Zewail City\n",
        "\n",
        "<br>\n",
        "\n",
        "<h1 align=\"center\">Lab 4</h3>\n",
        "<h1 align=\"center\">Training Neural Networks: Part I</h3>\n",
        "<h2 align=\"center\">Overfitting and Regularization</h2>\n",
        "<h3 align=\"center\">Shahd Seddik</h3>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ8jaDWAdsaA"
      },
      "source": [
        "#Lab Objectives\n",
        "* Understand the key steps when training a deep learning model.\n",
        "* Understand the relationship between model complexity and overfitting.\n",
        "* Learn how to detect overfitting and underfitting from a neural network's learning curve.\n",
        "* Learn how to avoid overfitting using different regularization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDsqIRl1YoC"
      },
      "source": [
        "# Steps of Training a Deep Learning Model\n",
        "\n",
        "1. Define your problem\n",
        "1. Prepare your data\n",
        "1. Choose your model and appropriately initialize it\n",
        "1. Train the chosen model\n",
        "1. Improve results\n",
        "1. Present results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ-PcmeCpfoR"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "One of the most often cited papers about deep learning in combination with a physics application:\n",
        "*Searching for Exotic Particles in High-Energy Physics with Deep Learning* by Pierre Baldi, Peter Sadowski, Daniel Whiteson.\n",
        "\n",
        "We will use the [Higgs Dataset](http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz) to train a binary classification model.\n",
        "\n",
        "The dataset contains 11,000,000 instances, with 28 features each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbe-ldDtZfhp"
      },
      "source": [
        "Download the dataset `HIGGS.h5` by running the cell below. An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data and is designed to store large amounts of data efficiently.\n",
        "\n",
        "Alternatively, you can download the compressed CSV file from [this link](https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz), and then extract it, but you will notice the file is much larger in size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbqzq90vZHhC",
        "outputId": "e36b20fb-7585-4633-8c05-023ce7b2db26"
      },
      "source": [
        "!wget http://mlphysics.ics.uci.edu/data/higgs/HIGGS.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-07 21:50:54--  http://mlphysics.ics.uci.edu/data/higgs/HIGGS.h5\n",
            "Resolving mlphysics.ics.uci.edu (mlphysics.ics.uci.edu)... 128.195.1.86\n",
            "Connecting to mlphysics.ics.uci.edu (mlphysics.ics.uci.edu)|128.195.1.86|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1276002144 (1.2G)\n",
            "Saving to: ‘HIGGS.h5.2’\n",
            "\n",
            "HIGGS.h5.2          100%[===================>]   1.19G  38.4MB/s    in 31s     \n",
            "\n",
            "2021-04-07 21:51:26 (38.8 MB/s) - ‘HIGGS.h5.2’ saved [1276002144/1276002144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ2f6xyzZQTd"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "file_ = h5py.File(\"HIGGS.h5\", 'r')\n",
        "inputs = np.array(file_[\"features\"])\n",
        "targets = np.array(file_[\"targets\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4J2h1RJYwGS",
        "outputId": "5c6cc5ac-88d7-478a-b238-d87e0f4bcee3"
      },
      "source": [
        "print(inputs.shape)\n",
        "print(targets.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11000000, 28)\n",
            "(11000000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUptyOnSJGt4"
      },
      "source": [
        "We will take a subset of the data to save time. Skip the next two cells if you want to use the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svjEFoQSJFtH"
      },
      "source": [
        "n_samples = 20000 # number of samples to take\n",
        "\n",
        "indices = np.random.randint(inputs.shape[0], size = n_samples) # generate random indices\n",
        "\n",
        "inputs = inputs[indices, :]\n",
        "targets = targets[indices, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tkio0DeKdAH",
        "outputId": "f42a3238-fd08-446c-9324-3d2ac5f69e6f"
      },
      "source": [
        "print(inputs.shape)\n",
        "print(targets.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 28)\n",
            "(20000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je9pYPrpPRPW"
      },
      "source": [
        "Let's take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKBERV-osKsZ",
        "outputId": "7e61f6e6-7e9d-4665-9f0e-949f49ce1ee4"
      },
      "source": [
        "FEATURES = inputs.shape[1]\n",
        "FEATURES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7gp6oRLaOyr",
        "outputId": "c532814c-73db-4659-eb8b-47d412033cfa"
      },
      "source": [
        "print(inputs[0])\n",
        "print(targets[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.57464856 -0.05557038 -0.8686017   0.84472203  0.05533941  0.52353525\n",
            " -0.33373293  0.7247294   0.          0.5265284  -1.7309275  -1.2796435\n",
            "  0.          0.86598885  0.91861373  0.19794606  2.5482244   1.4008081\n",
            "  1.3678678  -1.5923096   3.1019614   0.81071424  1.2019482   0.98394334\n",
            "  0.84728026  0.8835719   1.0804981   0.9243242 ]\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2njlmce9dbxN"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "Let's split our dataset into training and test sets.\n",
        "\n",
        "Then, we will fit a pre-processing function to standardize features by removing the mean and scaling to unit variance.\n",
        "\n",
        "The standard score of a sample $x$ is calculated as\n",
        "\n",
        "$z = (x - \\mu) / \\sigma$\n",
        "\n",
        "where $\\mu$ is the mean of the training samples, and $\\sigma$ is the standard deviation of the training samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdmPZVO-5978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78451baf-135c-48b7-89b3-7616ff5602a6"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        inputs, targets, test_size=0.10, random_state=42, shuffle=True)\n",
        "\n",
        "# Set up preprocessing \n",
        "preprocessing_input = StandardScaler()\n",
        "preprocessing_input.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNaayixgfCQL"
      },
      "source": [
        "# Overfitting and Underfitting\n",
        "\n",
        "Supervised machine learning can be thought of as approximating a target function $f$ that maps input point $X$ to output $y$ (i.e. $y=f(X)$).\n",
        "\n",
        "It is crucial that the learned function be able to generalize well over new, unseen data. This allows us to make accurate predictions in the future on data the model has never seen.\n",
        "\n",
        "So, what is overfitting? And when does it happen? (Discussion)\n",
        "\n",
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/1200px-Overfitting.svg.png\"\n",
        " width=\"200px\"> </center>\n",
        " \n",
        ">- Overfitting refers to the problem when a model learns (or memorizes) the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.\n",
        "- What is meant by the representational capacity of a model?\n",
        "- (Fill in the blank) Overfitting is more likely to happen when the model has ............... (larger/smaller) representational capacity.\n",
        "\n",
        "\n",
        "On the other hand, underfitting happens when the model is neither able to model the training data nor able to generalize to new data.\n",
        "\n",
        "To summarize:\n",
        "<center><img src=\"https://gblobscdn.gitbook.com/assets%2F-LvBP1svpACTB1R1x_U4%2F-LvNWUoWieQqaGmU_gl9%2F-LvNoby-llz4QzAK15nL%2Fimage.png?alt=media&token=41720ce9-bb66-4419-9bd8-640abf1fc415\"\n",
        " width=\"400px\"> </center>\n",
        "\n",
        " In the context of neural networks, overfitting and underfitting can be detected by looking at the training and validation loss during training.\n",
        " \n",
        "<center><img src=\"https://drek4537l1klr.cloudfront.net/cai/Figures/08fig06_alt.jpg\"\n",
        " width=\"600px\"> </center>\n",
        "\n",
        " >- (Q) Assuming the three graphs above were generated from three different models over the same dataset. Which model is the most complex? Which is the least?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIhSys2BwFBo"
      },
      "source": [
        "# Models\n",
        "\n",
        "Let's build neural nets to solve this classification problem! We will build 4 different models with varying complexities to explore overfitting and underfitting.\n",
        "\n",
        "Each model will use the same `compile` and `fit` methods, so let's code functions to make our code cleaner and more modular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Yr1AxMwOTf"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "BATCH_SIZE = 500\n",
        "EPOCHS = 200\n",
        "\n",
        "def get_optimizer():\n",
        "  return Adam()\n",
        "\n",
        "def compile_and_fit(model, optimizer=None, max_epochs=1000, callback = None):\n",
        "  if optimizer is None:\n",
        "    optimizer = get_optimizer()\n",
        "  \n",
        "  # Compile model and print summary\n",
        "  model.compile(optimizer = optimizer,\n",
        "                loss = \"binary_crossentropy\",\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # Fit model to training data\n",
        "  history = model.fit(\n",
        "    x = preprocessing_input.transform(X_train), # do not forget to normalize X\n",
        "    y = y_train,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = max_epochs,\n",
        "    validation_split = 0.1,\n",
        "    callbacks=callback)\n",
        "\n",
        "  return history\n",
        "\n",
        "# Create a dictionary to store the histories of all trained models\n",
        "model_histories = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS2ldugHoDwL"
      },
      "source": [
        "Now, let's get to building our 4 models! We will call them tiny model, small model, medium model, and large model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_6jdazun7iI"
      },
      "source": [
        "# Model 1\n",
        "tiny_model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(FEATURES,)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Model 2\n",
        "small_model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(FEATURES,)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Model 3\n",
        "medium_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(FEATURES,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Model 4\n",
        "large_model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(FEATURES,)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaZiw14l2PVC"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIcplKO72D76",
        "outputId": "639b4054-6234-433c-92ed-a9de5dfc80e7"
      },
      "source": [
        "model_histories['Tiny'] = compile_and_fit(tiny_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                464       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 481\n",
            "Trainable params: 481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 15ms/step - loss: 0.9513 - accuracy: 0.4685 - val_loss: 0.8218 - val_accuracy: 0.4761\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.4854 - val_loss: 0.7301 - val_accuracy: 0.5111\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.5131 - val_loss: 0.6962 - val_accuracy: 0.5361\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5509 - val_loss: 0.6801 - val_accuracy: 0.5667\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5749 - val_loss: 0.6704 - val_accuracy: 0.5872\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.5929 - val_loss: 0.6634 - val_accuracy: 0.6089\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6018 - val_loss: 0.6578 - val_accuracy: 0.6100\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6111 - val_loss: 0.6534 - val_accuracy: 0.6222\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6171 - val_loss: 0.6496 - val_accuracy: 0.6294\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6255 - val_loss: 0.6458 - val_accuracy: 0.6339\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6272 - val_loss: 0.6430 - val_accuracy: 0.6461\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6314 - val_loss: 0.6404 - val_accuracy: 0.6483\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6350 - val_loss: 0.6378 - val_accuracy: 0.6522\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6377 - val_loss: 0.6356 - val_accuracy: 0.6539\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6387 - val_loss: 0.6334 - val_accuracy: 0.6622\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6480 - val_loss: 0.6320 - val_accuracy: 0.6600\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6495 - val_loss: 0.6301 - val_accuracy: 0.6617\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6554 - val_loss: 0.6285 - val_accuracy: 0.6706\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6535 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6534 - val_loss: 0.6263 - val_accuracy: 0.6694\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6489 - val_loss: 0.6252 - val_accuracy: 0.6706\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6576 - val_loss: 0.6244 - val_accuracy: 0.6689\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6603 - val_loss: 0.6232 - val_accuracy: 0.6683\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.6570 - val_loss: 0.6226 - val_accuracy: 0.6667\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6608 - val_loss: 0.6220 - val_accuracy: 0.6650\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6574 - val_loss: 0.6208 - val_accuracy: 0.6639\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6636 - val_loss: 0.6204 - val_accuracy: 0.6694\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6672 - val_loss: 0.6201 - val_accuracy: 0.6694\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6701 - val_loss: 0.6192 - val_accuracy: 0.6728\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6625 - val_loss: 0.6185 - val_accuracy: 0.6722\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6637 - val_loss: 0.6182 - val_accuracy: 0.6706\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6715 - val_loss: 0.6177 - val_accuracy: 0.6694\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6670 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6682 - val_loss: 0.6167 - val_accuracy: 0.6722\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6715 - val_loss: 0.6162 - val_accuracy: 0.6689\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6717 - val_loss: 0.6161 - val_accuracy: 0.6711\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6780 - val_loss: 0.6159 - val_accuracy: 0.6700\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6747 - val_loss: 0.6150 - val_accuracy: 0.6694\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6732 - val_loss: 0.6158 - val_accuracy: 0.6661\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6733 - val_loss: 0.6149 - val_accuracy: 0.6739\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6779 - val_loss: 0.6149 - val_accuracy: 0.6739\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.6792 - val_loss: 0.6144 - val_accuracy: 0.6700\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.6792 - val_loss: 0.6144 - val_accuracy: 0.6717\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.6753 - val_loss: 0.6145 - val_accuracy: 0.6694\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.6849 - val_loss: 0.6138 - val_accuracy: 0.6722\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6835 - val_loss: 0.6142 - val_accuracy: 0.6667\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6837 - val_loss: 0.6142 - val_accuracy: 0.6667\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6838 - val_loss: 0.6132 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6854 - val_loss: 0.6138 - val_accuracy: 0.6683\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6848 - val_loss: 0.6130 - val_accuracy: 0.6678\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6823 - val_loss: 0.6131 - val_accuracy: 0.6644\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6816 - val_loss: 0.6137 - val_accuracy: 0.6694\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6896 - val_loss: 0.6129 - val_accuracy: 0.6689\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6891 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6845 - val_loss: 0.6137 - val_accuracy: 0.6644\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6865 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6828 - val_loss: 0.6134 - val_accuracy: 0.6650\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.6927 - val_loss: 0.6135 - val_accuracy: 0.6656\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6844 - val_loss: 0.6139 - val_accuracy: 0.6683\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6876 - val_loss: 0.6130 - val_accuracy: 0.6678\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6843 - val_loss: 0.6135 - val_accuracy: 0.6700\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6849 - val_loss: 0.6137 - val_accuracy: 0.6711\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6889 - val_loss: 0.6135 - val_accuracy: 0.6711\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6923 - val_loss: 0.6133 - val_accuracy: 0.6683\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6917 - val_loss: 0.6134 - val_accuracy: 0.6706\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.6879 - val_loss: 0.6139 - val_accuracy: 0.6689\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6877 - val_loss: 0.6136 - val_accuracy: 0.6689\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6881 - val_loss: 0.6134 - val_accuracy: 0.6672\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.6863 - val_loss: 0.6135 - val_accuracy: 0.6717\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6918 - val_loss: 0.6136 - val_accuracy: 0.6717\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6918 - val_loss: 0.6132 - val_accuracy: 0.6700\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6866 - val_loss: 0.6135 - val_accuracy: 0.6711\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6870 - val_loss: 0.6139 - val_accuracy: 0.6700\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6904 - val_loss: 0.6137 - val_accuracy: 0.6706\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6890 - val_loss: 0.6129 - val_accuracy: 0.6728\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6845 - val_loss: 0.6128 - val_accuracy: 0.6739\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6944 - val_loss: 0.6130 - val_accuracy: 0.6744\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.6914 - val_loss: 0.6132 - val_accuracy: 0.6750\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6915 - val_loss: 0.6125 - val_accuracy: 0.6722\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.6962 - val_loss: 0.6127 - val_accuracy: 0.6761\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.6999 - val_loss: 0.6128 - val_accuracy: 0.6750\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7013 - val_loss: 0.6128 - val_accuracy: 0.6744\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6985 - val_loss: 0.6122 - val_accuracy: 0.6744\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.6959 - val_loss: 0.6132 - val_accuracy: 0.6733\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7008 - val_loss: 0.6127 - val_accuracy: 0.6744\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.6950 - val_loss: 0.6125 - val_accuracy: 0.6733\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6972 - val_loss: 0.6125 - val_accuracy: 0.6778\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6928 - val_loss: 0.6122 - val_accuracy: 0.6722\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.6981 - val_loss: 0.6126 - val_accuracy: 0.6722\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6981 - val_loss: 0.6122 - val_accuracy: 0.6761\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7005 - val_loss: 0.6123 - val_accuracy: 0.6739\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7019 - val_loss: 0.6120 - val_accuracy: 0.6756\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6897 - val_loss: 0.6129 - val_accuracy: 0.6744\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7047 - val_loss: 0.6122 - val_accuracy: 0.6722\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7000 - val_loss: 0.6119 - val_accuracy: 0.6756\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.6924 - val_loss: 0.6119 - val_accuracy: 0.6772\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7040 - val_loss: 0.6111 - val_accuracy: 0.6783\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6979 - val_loss: 0.6117 - val_accuracy: 0.6739\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6936 - val_loss: 0.6117 - val_accuracy: 0.6772\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7014 - val_loss: 0.6120 - val_accuracy: 0.6761\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6972 - val_loss: 0.6122 - val_accuracy: 0.6789\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6992 - val_loss: 0.6116 - val_accuracy: 0.6756\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7015 - val_loss: 0.6123 - val_accuracy: 0.6811\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7012 - val_loss: 0.6110 - val_accuracy: 0.6778\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6984 - val_loss: 0.6109 - val_accuracy: 0.6833\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.6988 - val_loss: 0.6105 - val_accuracy: 0.6833\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6928 - val_loss: 0.6115 - val_accuracy: 0.6828\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6975 - val_loss: 0.6104 - val_accuracy: 0.6856\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.6937 - val_loss: 0.6113 - val_accuracy: 0.6794\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7066 - val_loss: 0.6103 - val_accuracy: 0.6806\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7032 - val_loss: 0.6109 - val_accuracy: 0.6839\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6956 - val_loss: 0.6103 - val_accuracy: 0.6828\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6978 - val_loss: 0.6104 - val_accuracy: 0.6811\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7001 - val_loss: 0.6110 - val_accuracy: 0.6811\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7034 - val_loss: 0.6105 - val_accuracy: 0.6822\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.6976 - val_loss: 0.6101 - val_accuracy: 0.6811\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7031 - val_loss: 0.6103 - val_accuracy: 0.6828\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7011 - val_loss: 0.6105 - val_accuracy: 0.6794\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7070 - val_loss: 0.6099 - val_accuracy: 0.6811\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7087 - val_loss: 0.6096 - val_accuracy: 0.6828\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6995 - val_loss: 0.6096 - val_accuracy: 0.6800\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.6945 - val_loss: 0.6102 - val_accuracy: 0.6811\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7097 - val_loss: 0.6102 - val_accuracy: 0.6783\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7050 - val_loss: 0.6098 - val_accuracy: 0.6839\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7064 - val_loss: 0.6099 - val_accuracy: 0.6767\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7007 - val_loss: 0.6102 - val_accuracy: 0.6806\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7044 - val_loss: 0.6092 - val_accuracy: 0.6828\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7049 - val_loss: 0.6102 - val_accuracy: 0.6811\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7045 - val_loss: 0.6094 - val_accuracy: 0.6811\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7065 - val_loss: 0.6098 - val_accuracy: 0.6794\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7021 - val_loss: 0.6092 - val_accuracy: 0.6844\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7070 - val_loss: 0.6095 - val_accuracy: 0.6817\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7012 - val_loss: 0.6100 - val_accuracy: 0.6828\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7091 - val_loss: 0.6085 - val_accuracy: 0.6850\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7044 - val_loss: 0.6088 - val_accuracy: 0.6789\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7006 - val_loss: 0.6100 - val_accuracy: 0.6817\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7092 - val_loss: 0.6084 - val_accuracy: 0.6822\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7002 - val_loss: 0.6089 - val_accuracy: 0.6861\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7090 - val_loss: 0.6084 - val_accuracy: 0.6822\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7051 - val_loss: 0.6089 - val_accuracy: 0.6828\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7070 - val_loss: 0.6081 - val_accuracy: 0.6811\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7036 - val_loss: 0.6087 - val_accuracy: 0.6839\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7085 - val_loss: 0.6085 - val_accuracy: 0.6811\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7079 - val_loss: 0.6084 - val_accuracy: 0.6822\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7092 - val_loss: 0.6089 - val_accuracy: 0.6839\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7070 - val_loss: 0.6080 - val_accuracy: 0.6839\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7146 - val_loss: 0.6093 - val_accuracy: 0.6850\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7027 - val_loss: 0.6086 - val_accuracy: 0.6844\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7087 - val_loss: 0.6081 - val_accuracy: 0.6878\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7084 - val_loss: 0.6087 - val_accuracy: 0.6850\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7026 - val_loss: 0.6084 - val_accuracy: 0.6878\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7073 - val_loss: 0.6079 - val_accuracy: 0.6856\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7079 - val_loss: 0.6085 - val_accuracy: 0.6894\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7079 - val_loss: 0.6090 - val_accuracy: 0.6861\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7089 - val_loss: 0.6082 - val_accuracy: 0.6883\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7089 - val_loss: 0.6081 - val_accuracy: 0.6856\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7075 - val_loss: 0.6078 - val_accuracy: 0.6867\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7130 - val_loss: 0.6081 - val_accuracy: 0.6883\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7084 - val_loss: 0.6080 - val_accuracy: 0.6872\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7172 - val_loss: 0.6081 - val_accuracy: 0.6856\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7085 - val_loss: 0.6077 - val_accuracy: 0.6878\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7136 - val_loss: 0.6073 - val_accuracy: 0.6878\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7111 - val_loss: 0.6078 - val_accuracy: 0.6900\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7150 - val_loss: 0.6081 - val_accuracy: 0.6894\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7078 - val_loss: 0.6082 - val_accuracy: 0.6856\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7181 - val_loss: 0.6082 - val_accuracy: 0.6900\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7109 - val_loss: 0.6071 - val_accuracy: 0.6900\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7087 - val_loss: 0.6077 - val_accuracy: 0.6889\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7086 - val_loss: 0.6072 - val_accuracy: 0.6917\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7155 - val_loss: 0.6076 - val_accuracy: 0.6900\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7127 - val_loss: 0.6074 - val_accuracy: 0.6928\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7122 - val_loss: 0.6074 - val_accuracy: 0.6911\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7113 - val_loss: 0.6075 - val_accuracy: 0.6906\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7166 - val_loss: 0.6073 - val_accuracy: 0.6906\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7125 - val_loss: 0.6076 - val_accuracy: 0.6933\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7094 - val_loss: 0.6073 - val_accuracy: 0.6922\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7117 - val_loss: 0.6072 - val_accuracy: 0.6950\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7191 - val_loss: 0.6077 - val_accuracy: 0.6928\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7223 - val_loss: 0.6074 - val_accuracy: 0.6950\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7097 - val_loss: 0.6078 - val_accuracy: 0.6933\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7125 - val_loss: 0.6076 - val_accuracy: 0.6906\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7071 - val_loss: 0.6075 - val_accuracy: 0.6961\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7169 - val_loss: 0.6073 - val_accuracy: 0.6933\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7155 - val_loss: 0.6072 - val_accuracy: 0.6928\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7111 - val_loss: 0.6073 - val_accuracy: 0.6911\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7118 - val_loss: 0.6069 - val_accuracy: 0.6933\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7133 - val_loss: 0.6076 - val_accuracy: 0.6928\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7172 - val_loss: 0.6068 - val_accuracy: 0.6906\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7056 - val_loss: 0.6066 - val_accuracy: 0.6917\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7082 - val_loss: 0.6069 - val_accuracy: 0.6894\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7135 - val_loss: 0.6068 - val_accuracy: 0.6922\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7047 - val_loss: 0.6072 - val_accuracy: 0.6939\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7110 - val_loss: 0.6074 - val_accuracy: 0.6917\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7139 - val_loss: 0.6069 - val_accuracy: 0.6939\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7128 - val_loss: 0.6062 - val_accuracy: 0.6917\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7137 - val_loss: 0.6068 - val_accuracy: 0.6939\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7154 - val_loss: 0.6065 - val_accuracy: 0.6872\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7122 - val_loss: 0.6065 - val_accuracy: 0.6928\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7162 - val_loss: 0.6072 - val_accuracy: 0.6911\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7118 - val_loss: 0.6062 - val_accuracy: 0.6939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlSladpspALa",
        "outputId": "08293445-aeb8-4026-9933-2461eadc41ba"
      },
      "source": [
        "model_histories['Small'] = compile_and_fit(small_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 16)                464       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 753\n",
            "Trainable params: 753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 7ms/step - loss: 0.7906 - accuracy: 0.4943 - val_loss: 0.7155 - val_accuracy: 0.5144\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.5340 - val_loss: 0.6887 - val_accuracy: 0.5528\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5639 - val_loss: 0.6766 - val_accuracy: 0.5883\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5866 - val_loss: 0.6680 - val_accuracy: 0.6067\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6024 - val_loss: 0.6616 - val_accuracy: 0.6150\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6111 - val_loss: 0.6564 - val_accuracy: 0.6244\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6208 - val_loss: 0.6523 - val_accuracy: 0.6317\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6210 - val_loss: 0.6489 - val_accuracy: 0.6383\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6291 - val_loss: 0.6465 - val_accuracy: 0.6350\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6297 - val_loss: 0.6442 - val_accuracy: 0.6406\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6344 - val_loss: 0.6424 - val_accuracy: 0.6394\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6449 - val_loss: 0.6409 - val_accuracy: 0.6383\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6332 - val_loss: 0.6392 - val_accuracy: 0.6422\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6415 - val_loss: 0.6377 - val_accuracy: 0.6422\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6443 - val_loss: 0.6369 - val_accuracy: 0.6456\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6507 - val_loss: 0.6347 - val_accuracy: 0.6494\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6492 - val_loss: 0.6340 - val_accuracy: 0.6444\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6549 - val_loss: 0.6334 - val_accuracy: 0.6467\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6488 - val_loss: 0.6309 - val_accuracy: 0.6539\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6518 - val_loss: 0.6296 - val_accuracy: 0.6567\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6546 - val_loss: 0.6280 - val_accuracy: 0.6589\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6521 - val_loss: 0.6275 - val_accuracy: 0.6594\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6265 - val_accuracy: 0.6683\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6674 - val_loss: 0.6249 - val_accuracy: 0.6683\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6646 - val_loss: 0.6245 - val_accuracy: 0.6717\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6742 - val_loss: 0.6229 - val_accuracy: 0.6689\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6733 - val_loss: 0.6231 - val_accuracy: 0.6617\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6771 - val_loss: 0.6226 - val_accuracy: 0.6683\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6794 - val_loss: 0.6223 - val_accuracy: 0.6672\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6836 - val_loss: 0.6200 - val_accuracy: 0.6717\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6788 - val_loss: 0.6188 - val_accuracy: 0.6722\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6836 - val_loss: 0.6184 - val_accuracy: 0.6717\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6816 - val_loss: 0.6174 - val_accuracy: 0.6750\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6854 - val_loss: 0.6168 - val_accuracy: 0.6694\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6865 - val_loss: 0.6160 - val_accuracy: 0.6728\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6865 - val_loss: 0.6159 - val_accuracy: 0.6733\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.6930 - val_loss: 0.6145 - val_accuracy: 0.6750\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6878 - val_loss: 0.6144 - val_accuracy: 0.6756\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6875 - val_loss: 0.6136 - val_accuracy: 0.6744\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6847 - val_loss: 0.6129 - val_accuracy: 0.6733\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6919 - val_loss: 0.6134 - val_accuracy: 0.6756\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6899 - val_loss: 0.6123 - val_accuracy: 0.6783\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6951 - val_loss: 0.6119 - val_accuracy: 0.6761\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7006 - val_loss: 0.6111 - val_accuracy: 0.6739\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6912 - val_loss: 0.6107 - val_accuracy: 0.6744\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6936 - val_loss: 0.6104 - val_accuracy: 0.6733\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6980 - val_loss: 0.6107 - val_accuracy: 0.6789\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.6960 - val_loss: 0.6100 - val_accuracy: 0.6767\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.6958 - val_loss: 0.6100 - val_accuracy: 0.6833\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.6948 - val_loss: 0.6099 - val_accuracy: 0.6822\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6966 - val_loss: 0.6103 - val_accuracy: 0.6833\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.6997 - val_loss: 0.6104 - val_accuracy: 0.6817\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7014 - val_loss: 0.6103 - val_accuracy: 0.6817\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7055 - val_loss: 0.6093 - val_accuracy: 0.6811\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7002 - val_loss: 0.6093 - val_accuracy: 0.6861\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6998 - val_loss: 0.6092 - val_accuracy: 0.6856\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7080 - val_loss: 0.6079 - val_accuracy: 0.6883\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7110 - val_loss: 0.6067 - val_accuracy: 0.6856\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7095 - val_loss: 0.6076 - val_accuracy: 0.6894\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7085 - val_loss: 0.6069 - val_accuracy: 0.6844\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7030 - val_loss: 0.6074 - val_accuracy: 0.6883\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7112 - val_loss: 0.6066 - val_accuracy: 0.6878\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7080 - val_loss: 0.6058 - val_accuracy: 0.6900\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7062 - val_loss: 0.6061 - val_accuracy: 0.6878\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7110 - val_loss: 0.6072 - val_accuracy: 0.6850\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7056 - val_loss: 0.6062 - val_accuracy: 0.6833\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7119 - val_loss: 0.6055 - val_accuracy: 0.6839\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7164 - val_loss: 0.6061 - val_accuracy: 0.6872\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7095 - val_loss: 0.6060 - val_accuracy: 0.6806\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7131 - val_loss: 0.6074 - val_accuracy: 0.6889\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7164 - val_loss: 0.6051 - val_accuracy: 0.6844\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7135 - val_loss: 0.6053 - val_accuracy: 0.6833\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7141 - val_loss: 0.6066 - val_accuracy: 0.6861\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7219 - val_loss: 0.6070 - val_accuracy: 0.6828\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7201 - val_loss: 0.6052 - val_accuracy: 0.6822\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7166 - val_loss: 0.6061 - val_accuracy: 0.6817\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7179 - val_loss: 0.6059 - val_accuracy: 0.6833\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7126 - val_loss: 0.6048 - val_accuracy: 0.6789\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7102 - val_loss: 0.6067 - val_accuracy: 0.6850\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7112 - val_loss: 0.6059 - val_accuracy: 0.6867\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7141 - val_loss: 0.6058 - val_accuracy: 0.6767\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7156 - val_loss: 0.6065 - val_accuracy: 0.6850\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7145 - val_loss: 0.6057 - val_accuracy: 0.6739\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7181 - val_loss: 0.6058 - val_accuracy: 0.6794\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7199 - val_loss: 0.6060 - val_accuracy: 0.6856\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7184 - val_loss: 0.6063 - val_accuracy: 0.6861\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7165 - val_loss: 0.6053 - val_accuracy: 0.6833\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7205 - val_loss: 0.6065 - val_accuracy: 0.6817\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7148 - val_loss: 0.6073 - val_accuracy: 0.6833\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7234 - val_loss: 0.6067 - val_accuracy: 0.6822\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7152 - val_loss: 0.6069 - val_accuracy: 0.6844\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7134 - val_loss: 0.6086 - val_accuracy: 0.6811\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7178 - val_loss: 0.6085 - val_accuracy: 0.6828\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7240 - val_loss: 0.6071 - val_accuracy: 0.6800\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7284 - val_loss: 0.6072 - val_accuracy: 0.6817\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7223 - val_loss: 0.6067 - val_accuracy: 0.6800\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7162 - val_loss: 0.6071 - val_accuracy: 0.6794\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7236 - val_loss: 0.6075 - val_accuracy: 0.6828\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7218 - val_loss: 0.6086 - val_accuracy: 0.6844\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7161 - val_loss: 0.6080 - val_accuracy: 0.6828\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7221 - val_loss: 0.6074 - val_accuracy: 0.6778\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7137 - val_loss: 0.6081 - val_accuracy: 0.6800\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7270 - val_loss: 0.6081 - val_accuracy: 0.6789\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7269 - val_loss: 0.6081 - val_accuracy: 0.6794\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7226 - val_loss: 0.6084 - val_accuracy: 0.6772\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7263 - val_loss: 0.6076 - val_accuracy: 0.6811\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7211 - val_loss: 0.6079 - val_accuracy: 0.6794\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7191 - val_loss: 0.6070 - val_accuracy: 0.6822\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7204 - val_loss: 0.6086 - val_accuracy: 0.6850\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7230 - val_loss: 0.6080 - val_accuracy: 0.6844\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7285 - val_loss: 0.6080 - val_accuracy: 0.6856\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7244 - val_loss: 0.6085 - val_accuracy: 0.6861\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7255 - val_loss: 0.6088 - val_accuracy: 0.6850\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7238 - val_loss: 0.6081 - val_accuracy: 0.6822\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7262 - val_loss: 0.6082 - val_accuracy: 0.6844\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7223 - val_loss: 0.6089 - val_accuracy: 0.6817\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7260 - val_loss: 0.6080 - val_accuracy: 0.6822\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7220 - val_loss: 0.6095 - val_accuracy: 0.6861\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7210 - val_loss: 0.6083 - val_accuracy: 0.6800\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7274 - val_loss: 0.6086 - val_accuracy: 0.6800\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7197 - val_loss: 0.6090 - val_accuracy: 0.6800\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7206 - val_loss: 0.6082 - val_accuracy: 0.6811\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7256 - val_loss: 0.6095 - val_accuracy: 0.6861\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7245 - val_loss: 0.6081 - val_accuracy: 0.6756\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7307 - val_loss: 0.6080 - val_accuracy: 0.6794\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7202 - val_loss: 0.6082 - val_accuracy: 0.6778\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7300 - val_loss: 0.6093 - val_accuracy: 0.6800\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7277 - val_loss: 0.6086 - val_accuracy: 0.6794\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7218 - val_loss: 0.6087 - val_accuracy: 0.6811\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7240 - val_loss: 0.6097 - val_accuracy: 0.6828\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7220 - val_loss: 0.6091 - val_accuracy: 0.6794\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7296 - val_loss: 0.6088 - val_accuracy: 0.6789\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7228 - val_loss: 0.6087 - val_accuracy: 0.6761\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7237 - val_loss: 0.6091 - val_accuracy: 0.6800\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7263 - val_loss: 0.6089 - val_accuracy: 0.6800\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7239 - val_loss: 0.6102 - val_accuracy: 0.6828\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7266 - val_loss: 0.6095 - val_accuracy: 0.6800\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7238 - val_loss: 0.6087 - val_accuracy: 0.6772\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7250 - val_loss: 0.6084 - val_accuracy: 0.6794\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7259 - val_loss: 0.6104 - val_accuracy: 0.6800\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7238 - val_loss: 0.6105 - val_accuracy: 0.6789\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7211 - val_loss: 0.6089 - val_accuracy: 0.6778\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7265 - val_loss: 0.6107 - val_accuracy: 0.6794\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7292 - val_loss: 0.6093 - val_accuracy: 0.6772\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7271 - val_loss: 0.6106 - val_accuracy: 0.6817\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7344 - val_loss: 0.6098 - val_accuracy: 0.6811\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7265 - val_loss: 0.6108 - val_accuracy: 0.6806\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7273 - val_loss: 0.6100 - val_accuracy: 0.6800\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7251 - val_loss: 0.6118 - val_accuracy: 0.6806\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7250 - val_loss: 0.6112 - val_accuracy: 0.6822\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7279 - val_loss: 0.6112 - val_accuracy: 0.6828\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7256 - val_loss: 0.6115 - val_accuracy: 0.6806\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7224 - val_loss: 0.6112 - val_accuracy: 0.6817\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7265 - val_loss: 0.6108 - val_accuracy: 0.6800\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7277 - val_loss: 0.6116 - val_accuracy: 0.6833\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7300 - val_loss: 0.6110 - val_accuracy: 0.6817\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7273 - val_loss: 0.6122 - val_accuracy: 0.6761\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7275 - val_loss: 0.6111 - val_accuracy: 0.6789\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7294 - val_loss: 0.6122 - val_accuracy: 0.6783\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7259 - val_loss: 0.6110 - val_accuracy: 0.6811\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7301 - val_loss: 0.6125 - val_accuracy: 0.6811\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7332 - val_loss: 0.6120 - val_accuracy: 0.6778\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7348 - val_loss: 0.6114 - val_accuracy: 0.6794\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7283 - val_loss: 0.6127 - val_accuracy: 0.6783\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7240 - val_loss: 0.6140 - val_accuracy: 0.6772\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7276 - val_loss: 0.6115 - val_accuracy: 0.6756\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7300 - val_loss: 0.6128 - val_accuracy: 0.6778\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7321 - val_loss: 0.6132 - val_accuracy: 0.6778\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7329 - val_loss: 0.6140 - val_accuracy: 0.6761\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7250 - val_loss: 0.6132 - val_accuracy: 0.6756\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7276 - val_loss: 0.6130 - val_accuracy: 0.6789\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7304 - val_loss: 0.6122 - val_accuracy: 0.6778\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7269 - val_loss: 0.6132 - val_accuracy: 0.6733\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7266 - val_loss: 0.6133 - val_accuracy: 0.6783\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7192 - val_loss: 0.6134 - val_accuracy: 0.6767\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7331 - val_loss: 0.6148 - val_accuracy: 0.6783\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7277 - val_loss: 0.6155 - val_accuracy: 0.6767\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7283 - val_loss: 0.6135 - val_accuracy: 0.6778\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7235 - val_loss: 0.6159 - val_accuracy: 0.6789\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7259 - val_loss: 0.6137 - val_accuracy: 0.6756\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7333 - val_loss: 0.6152 - val_accuracy: 0.6750\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7300 - val_loss: 0.6140 - val_accuracy: 0.6778\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7219 - val_loss: 0.6150 - val_accuracy: 0.6761\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7275 - val_loss: 0.6144 - val_accuracy: 0.6739\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7338 - val_loss: 0.6169 - val_accuracy: 0.6767\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7328 - val_loss: 0.6139 - val_accuracy: 0.6772\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7342 - val_loss: 0.6135 - val_accuracy: 0.6772\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7318 - val_loss: 0.6152 - val_accuracy: 0.6772\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7325 - val_loss: 0.6149 - val_accuracy: 0.6761\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7279 - val_loss: 0.6139 - val_accuracy: 0.6767\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7316 - val_loss: 0.6145 - val_accuracy: 0.6739\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7302 - val_loss: 0.6147 - val_accuracy: 0.6761\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7326 - val_loss: 0.6143 - val_accuracy: 0.6778\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7292 - val_loss: 0.6143 - val_accuracy: 0.6744\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7322 - val_loss: 0.6148 - val_accuracy: 0.6778\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7270 - val_loss: 0.6148 - val_accuracy: 0.6761\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7300 - val_loss: 0.6134 - val_accuracy: 0.6778\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7326 - val_loss: 0.6138 - val_accuracy: 0.6767\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7274 - val_loss: 0.6145 - val_accuracy: 0.6756\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7322 - val_loss: 0.6140 - val_accuracy: 0.6783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDv5iuM-pOgY",
        "outputId": "c9c79039-f6c4-4ca9-c844-e45b31eca50e"
      },
      "source": [
        "model_histories['Medium']  = compile_and_fit(medium_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 64)                1856      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,241\n",
            "Trainable params: 10,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5342 - val_loss: 0.6660 - val_accuracy: 0.6117\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6126 - val_loss: 0.6432 - val_accuracy: 0.6422\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6386 - val_loss: 0.6369 - val_accuracy: 0.6589\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6470 - val_loss: 0.6307 - val_accuracy: 0.6606\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6660 - val_loss: 0.6276 - val_accuracy: 0.6683\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.6736 - val_loss: 0.6265 - val_accuracy: 0.6644\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.6835 - val_loss: 0.6230 - val_accuracy: 0.6678\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6890 - val_loss: 0.6250 - val_accuracy: 0.6656\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6936 - val_loss: 0.6215 - val_accuracy: 0.6683\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6955 - val_loss: 0.6207 - val_accuracy: 0.6706\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7134 - val_loss: 0.6209 - val_accuracy: 0.6706\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7106 - val_loss: 0.6200 - val_accuracy: 0.6667\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7179 - val_loss: 0.6302 - val_accuracy: 0.6522\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7200 - val_loss: 0.6245 - val_accuracy: 0.6650\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7275 - val_loss: 0.6236 - val_accuracy: 0.6600\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7245 - val_loss: 0.6269 - val_accuracy: 0.6667\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7321 - val_loss: 0.6292 - val_accuracy: 0.6578\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7404 - val_loss: 0.6365 - val_accuracy: 0.6517\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7403 - val_loss: 0.6346 - val_accuracy: 0.6611\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7498 - val_loss: 0.6394 - val_accuracy: 0.6600\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7509 - val_loss: 0.6389 - val_accuracy: 0.6622\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7548 - val_loss: 0.6483 - val_accuracy: 0.6533\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.6473 - val_accuracy: 0.6567\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7497 - val_loss: 0.6499 - val_accuracy: 0.6522\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7586 - val_loss: 0.6505 - val_accuracy: 0.6639\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7703 - val_loss: 0.6603 - val_accuracy: 0.6461\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7648 - val_loss: 0.6580 - val_accuracy: 0.6506\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7739 - val_loss: 0.6596 - val_accuracy: 0.6456\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7775 - val_loss: 0.6695 - val_accuracy: 0.6522\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7809 - val_loss: 0.6702 - val_accuracy: 0.6456\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7746 - val_loss: 0.6826 - val_accuracy: 0.6517\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7835 - val_loss: 0.6859 - val_accuracy: 0.6483\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7854 - val_loss: 0.6854 - val_accuracy: 0.6539\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7849 - val_loss: 0.6831 - val_accuracy: 0.6444\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7822 - val_loss: 0.6866 - val_accuracy: 0.6467\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7876 - val_loss: 0.6954 - val_accuracy: 0.6467\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7992 - val_loss: 0.7003 - val_accuracy: 0.6556\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7980 - val_loss: 0.7081 - val_accuracy: 0.6444\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7927 - val_loss: 0.7076 - val_accuracy: 0.6361\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7933 - val_loss: 0.7084 - val_accuracy: 0.6439\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8012 - val_loss: 0.7132 - val_accuracy: 0.6372\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8039 - val_loss: 0.7128 - val_accuracy: 0.6461\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8024 - val_loss: 0.7319 - val_accuracy: 0.6389\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7965 - val_loss: 0.7221 - val_accuracy: 0.6339\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8028 - val_loss: 0.7206 - val_accuracy: 0.6378\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8134 - val_loss: 0.7296 - val_accuracy: 0.6350\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8123 - val_loss: 0.7520 - val_accuracy: 0.6361\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8116 - val_loss: 0.7356 - val_accuracy: 0.6350\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8071 - val_loss: 0.7393 - val_accuracy: 0.6400\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8154 - val_loss: 0.7441 - val_accuracy: 0.6389\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8202 - val_loss: 0.7490 - val_accuracy: 0.6339\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8165 - val_loss: 0.7566 - val_accuracy: 0.6294\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8240 - val_loss: 0.7539 - val_accuracy: 0.6372\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8233 - val_loss: 0.7623 - val_accuracy: 0.6306\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8223 - val_loss: 0.7741 - val_accuracy: 0.6261\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8275 - val_loss: 0.7788 - val_accuracy: 0.6317\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8307 - val_loss: 0.7810 - val_accuracy: 0.6250\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8241 - val_loss: 0.7754 - val_accuracy: 0.6311\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8333 - val_loss: 0.7828 - val_accuracy: 0.6394\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8359 - val_loss: 0.7815 - val_accuracy: 0.6333\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8320 - val_loss: 0.7932 - val_accuracy: 0.6411\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8325 - val_loss: 0.7971 - val_accuracy: 0.6289\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8322 - val_loss: 0.7969 - val_accuracy: 0.6294\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8374 - val_loss: 0.8095 - val_accuracy: 0.6289\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8444 - val_loss: 0.7960 - val_accuracy: 0.6306\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8416 - val_loss: 0.8300 - val_accuracy: 0.6167\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8406 - val_loss: 0.8166 - val_accuracy: 0.6356\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3553 - accuracy: 0.8417 - val_loss: 0.8156 - val_accuracy: 0.6322\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8471 - val_loss: 0.8467 - val_accuracy: 0.6228\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8383 - val_loss: 0.8293 - val_accuracy: 0.6272\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8485 - val_loss: 0.8313 - val_accuracy: 0.6256\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8460 - val_loss: 0.8341 - val_accuracy: 0.6228\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8469 - val_loss: 0.8366 - val_accuracy: 0.6278\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8474 - val_loss: 0.8445 - val_accuracy: 0.6333\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8489 - val_loss: 0.8423 - val_accuracy: 0.6278\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8516 - val_loss: 0.8573 - val_accuracy: 0.6217\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8553 - val_loss: 0.8528 - val_accuracy: 0.6244\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8554 - val_loss: 0.8557 - val_accuracy: 0.6250\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8602 - val_loss: 0.8597 - val_accuracy: 0.6300\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8615 - val_loss: 0.8652 - val_accuracy: 0.6294\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8571 - val_loss: 0.8841 - val_accuracy: 0.6239\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8588 - val_loss: 0.8762 - val_accuracy: 0.6317\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8619 - val_loss: 0.8846 - val_accuracy: 0.6239\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8625 - val_loss: 0.8990 - val_accuracy: 0.6183\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8627 - val_loss: 0.8905 - val_accuracy: 0.6250\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8657 - val_loss: 0.8994 - val_accuracy: 0.6244\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8609 - val_loss: 0.9059 - val_accuracy: 0.6206\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8635 - val_loss: 0.9000 - val_accuracy: 0.6294\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8728 - val_loss: 0.9041 - val_accuracy: 0.6300\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8699 - val_loss: 0.9059 - val_accuracy: 0.6217\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8720 - val_loss: 0.9190 - val_accuracy: 0.6244\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8694 - val_loss: 0.9193 - val_accuracy: 0.6189\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8663 - val_loss: 0.9325 - val_accuracy: 0.6250\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8741 - val_loss: 0.9617 - val_accuracy: 0.6133\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8696 - val_loss: 0.9289 - val_accuracy: 0.6239\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8692 - val_loss: 0.9339 - val_accuracy: 0.6200\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8739 - val_loss: 0.9516 - val_accuracy: 0.6222\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8776 - val_loss: 0.9417 - val_accuracy: 0.6383\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8769 - val_loss: 0.9410 - val_accuracy: 0.6306\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8794 - val_loss: 0.9555 - val_accuracy: 0.6244\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8797 - val_loss: 0.9667 - val_accuracy: 0.6239\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8797 - val_loss: 0.9608 - val_accuracy: 0.6189\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8804 - val_loss: 0.9813 - val_accuracy: 0.6200\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8814 - val_loss: 0.9605 - val_accuracy: 0.6322\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8877 - val_loss: 0.9826 - val_accuracy: 0.6189\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8791 - val_loss: 0.9836 - val_accuracy: 0.6217\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8829 - val_loss: 0.9790 - val_accuracy: 0.6350\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8817 - val_loss: 0.9844 - val_accuracy: 0.6244\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8842 - val_loss: 0.9945 - val_accuracy: 0.6267\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8863 - val_loss: 1.0040 - val_accuracy: 0.6206\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8817 - val_loss: 0.9869 - val_accuracy: 0.6294\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8923 - val_loss: 1.0065 - val_accuracy: 0.6283\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8925 - val_loss: 1.0066 - val_accuracy: 0.6300\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.8952 - val_loss: 1.0245 - val_accuracy: 0.6289\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.8947 - val_loss: 1.0197 - val_accuracy: 0.6233\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8949 - val_loss: 1.0388 - val_accuracy: 0.6244\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8882 - val_loss: 1.0288 - val_accuracy: 0.6178\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.8928 - val_loss: 1.0215 - val_accuracy: 0.6294\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8958 - val_loss: 1.0478 - val_accuracy: 0.6228\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8937 - val_loss: 1.0438 - val_accuracy: 0.6294\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.8978 - val_loss: 1.0569 - val_accuracy: 0.6222\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.9025 - val_loss: 1.0536 - val_accuracy: 0.6306\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.8998 - val_loss: 1.0739 - val_accuracy: 0.6289\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.9014 - val_loss: 1.0691 - val_accuracy: 0.6283\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9018 - val_loss: 1.0671 - val_accuracy: 0.6267\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9008 - val_loss: 1.0869 - val_accuracy: 0.6228\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9057 - val_loss: 1.0766 - val_accuracy: 0.6239\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8985 - val_loss: 1.1015 - val_accuracy: 0.6239\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.8985 - val_loss: 1.1038 - val_accuracy: 0.6289\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9018 - val_loss: 1.0947 - val_accuracy: 0.6211\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9041 - val_loss: 1.0960 - val_accuracy: 0.6272\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9045 - val_loss: 1.1327 - val_accuracy: 0.6250\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.8980 - val_loss: 1.1085 - val_accuracy: 0.6267\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9060 - val_loss: 1.1290 - val_accuracy: 0.6283\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9048 - val_loss: 1.1507 - val_accuracy: 0.6256\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.9009 - val_loss: 1.1329 - val_accuracy: 0.6261\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.9061 - val_loss: 1.1295 - val_accuracy: 0.6228\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9091 - val_loss: 1.1410 - val_accuracy: 0.6333\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9093 - val_loss: 1.1530 - val_accuracy: 0.6211\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9102 - val_loss: 1.1589 - val_accuracy: 0.6206\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.9056 - val_loss: 1.1472 - val_accuracy: 0.6211\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9155 - val_loss: 1.1584 - val_accuracy: 0.6272\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9107 - val_loss: 1.1657 - val_accuracy: 0.6239\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9166 - val_loss: 1.1981 - val_accuracy: 0.6228\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2168 - accuracy: 0.9163 - val_loss: 1.1912 - val_accuracy: 0.6167\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9155 - val_loss: 1.1895 - val_accuracy: 0.6178\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9150 - val_loss: 1.1916 - val_accuracy: 0.6289\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9146 - val_loss: 1.2064 - val_accuracy: 0.6239\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9172 - val_loss: 1.1901 - val_accuracy: 0.6217\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9170 - val_loss: 1.2149 - val_accuracy: 0.6222\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9189 - val_loss: 1.2267 - val_accuracy: 0.6228\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9146 - val_loss: 1.2295 - val_accuracy: 0.6183\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9220 - val_loss: 1.2267 - val_accuracy: 0.6144\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9211 - val_loss: 1.2320 - val_accuracy: 0.6217\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9220 - val_loss: 1.2520 - val_accuracy: 0.6294\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9169 - val_loss: 1.2502 - val_accuracy: 0.6206\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9201 - val_loss: 1.2405 - val_accuracy: 0.6267\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.9256 - val_loss: 1.2503 - val_accuracy: 0.6233\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9215 - val_loss: 1.2618 - val_accuracy: 0.6278\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9231 - val_loss: 1.2751 - val_accuracy: 0.6283\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9285 - val_loss: 1.2761 - val_accuracy: 0.6217\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2054 - accuracy: 0.9221 - val_loss: 1.2905 - val_accuracy: 0.6200\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9268 - val_loss: 1.3064 - val_accuracy: 0.6117\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9264 - val_loss: 1.2956 - val_accuracy: 0.6250\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9278 - val_loss: 1.3122 - val_accuracy: 0.6183\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9346 - val_loss: 1.3105 - val_accuracy: 0.6222\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9275 - val_loss: 1.3199 - val_accuracy: 0.6206\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9287 - val_loss: 1.3195 - val_accuracy: 0.6222\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9271 - val_loss: 1.3227 - val_accuracy: 0.6194\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9341 - val_loss: 1.3399 - val_accuracy: 0.6206\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9348 - val_loss: 1.3595 - val_accuracy: 0.6156\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9339 - val_loss: 1.3490 - val_accuracy: 0.6178\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9349 - val_loss: 1.3655 - val_accuracy: 0.6211\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9314 - val_loss: 1.3653 - val_accuracy: 0.6156\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9333 - val_loss: 1.3751 - val_accuracy: 0.6200\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9337 - val_loss: 1.3859 - val_accuracy: 0.6200\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9327 - val_loss: 1.3761 - val_accuracy: 0.6211\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9355 - val_loss: 1.3902 - val_accuracy: 0.6172\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9331 - val_loss: 1.3821 - val_accuracy: 0.6333\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9348 - val_loss: 1.3924 - val_accuracy: 0.6222\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9373 - val_loss: 1.3962 - val_accuracy: 0.6200\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9446 - val_loss: 1.4146 - val_accuracy: 0.6239\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9355 - val_loss: 1.4012 - val_accuracy: 0.6233\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9387 - val_loss: 1.4305 - val_accuracy: 0.6267\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9380 - val_loss: 1.4232 - val_accuracy: 0.6194\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9443 - val_loss: 1.4525 - val_accuracy: 0.6250\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9393 - val_loss: 1.4587 - val_accuracy: 0.6200\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9424 - val_loss: 1.4364 - val_accuracy: 0.6194\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9401 - val_loss: 1.4797 - val_accuracy: 0.6239\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9423 - val_loss: 1.4483 - val_accuracy: 0.6233\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9442 - val_loss: 1.4682 - val_accuracy: 0.6239\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9366 - val_loss: 1.5083 - val_accuracy: 0.6261\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9379 - val_loss: 1.4975 - val_accuracy: 0.6283\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9448 - val_loss: 1.4857 - val_accuracy: 0.6211\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9434 - val_loss: 1.4873 - val_accuracy: 0.6217\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9431 - val_loss: 1.5053 - val_accuracy: 0.6244\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9484 - val_loss: 1.5054 - val_accuracy: 0.6222\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9510 - val_loss: 1.5139 - val_accuracy: 0.6306\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9509 - val_loss: 1.5019 - val_accuracy: 0.6217\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9456 - val_loss: 1.5290 - val_accuracy: 0.6217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mclCkooBpYnh",
        "outputId": "cddb8ce7-2bef-4162-81ee-808deca29784"
      },
      "source": [
        "model_histories['Large'] = compile_and_fit(large_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 803,329\n",
            "Trainable params: 803,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 0.6644 - accuracy: 0.5884 - val_loss: 0.6298 - val_accuracy: 0.6472\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6686 - val_loss: 0.6140 - val_accuracy: 0.6744\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.6938 - val_loss: 0.6081 - val_accuracy: 0.6800\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7249 - val_loss: 0.6135 - val_accuracy: 0.6717\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7452 - val_loss: 0.6268 - val_accuracy: 0.6728\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7640 - val_loss: 0.6421 - val_accuracy: 0.6717\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7897 - val_loss: 0.6624 - val_accuracy: 0.6667\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8137 - val_loss: 0.7010 - val_accuracy: 0.6633\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8455 - val_loss: 0.7652 - val_accuracy: 0.6667\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8730 - val_loss: 0.8321 - val_accuracy: 0.6728\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.8916 - val_loss: 0.9422 - val_accuracy: 0.6633\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9188 - val_loss: 0.9814 - val_accuracy: 0.6539\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9346 - val_loss: 1.2569 - val_accuracy: 0.6650\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9471 - val_loss: 1.2636 - val_accuracy: 0.6494\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9622 - val_loss: 1.3129 - val_accuracy: 0.6378\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1389 - accuracy: 0.9458 - val_loss: 1.2651 - val_accuracy: 0.6372\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9719 - val_loss: 1.5725 - val_accuracy: 0.6544\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 1.7340 - val_accuracy: 0.6422\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 1.9192 - val_accuracy: 0.6567\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 1.9424 - val_accuracy: 0.6544\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 1.8149 - val_accuracy: 0.6467\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9842 - val_loss: 2.0050 - val_accuracy: 0.6450\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 2.1235 - val_accuracy: 0.6594\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 2.2353 - val_accuracy: 0.6544\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 2.1938 - val_accuracy: 0.6589\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 2.0917 - val_accuracy: 0.6578\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9762 - val_loss: 2.0413 - val_accuracy: 0.6539\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 1.9248 - val_accuracy: 0.6583\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 1.9597 - val_accuracy: 0.6578\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 2.1138 - val_accuracy: 0.6483\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 2.2117 - val_accuracy: 0.6633\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 2.3567 - val_accuracy: 0.6428\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 2.3974 - val_accuracy: 0.6644\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 2.3703 - val_accuracy: 0.6500\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9907 - val_loss: 2.2915 - val_accuracy: 0.6489\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 2.3869 - val_accuracy: 0.6533\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 2.5717 - val_accuracy: 0.6617\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 2.4717 - val_accuracy: 0.6556\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 2.2651 - val_accuracy: 0.6467\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9890 - val_loss: 2.3205 - val_accuracy: 0.6578\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 2.1800 - val_accuracy: 0.6589\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 2.1193 - val_accuracy: 0.6456\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 2.1148 - val_accuracy: 0.6539\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 2.3876 - val_accuracy: 0.6533\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 2.5150 - val_accuracy: 0.6539\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 2.5349 - val_accuracy: 0.6556\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 2.5705 - val_accuracy: 0.6678\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 2.6028 - val_accuracy: 0.6639\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 2.6522 - val_accuracy: 0.6517\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 2.6815 - val_accuracy: 0.6500\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 2.7114 - val_accuracy: 0.6600\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 2.5456 - val_accuracy: 0.6444\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 2.0632 - val_accuracy: 0.6461\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 2.0817 - val_accuracy: 0.6533\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 2.4154 - val_accuracy: 0.6383\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 2.4266 - val_accuracy: 0.6417\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 2.5723 - val_accuracy: 0.6594\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 2.6027 - val_accuracy: 0.6450\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 2.4198 - val_accuracy: 0.6506\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 2.5931 - val_accuracy: 0.6483\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 2.6118 - val_accuracy: 0.6422\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 2.7222 - val_accuracy: 0.6500\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 2.6001 - val_accuracy: 0.6378\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 2.4961 - val_accuracy: 0.6606\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 2.5775 - val_accuracy: 0.6494\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 2.6651 - val_accuracy: 0.6572\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 2.7493 - val_accuracy: 0.6344\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 2.8037 - val_accuracy: 0.6394\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 2.8354 - val_accuracy: 0.6394\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 2.9362 - val_accuracy: 0.6517\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 2.9737 - val_accuracy: 0.6561\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 2.9959 - val_accuracy: 0.6394\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 2.9250 - val_accuracy: 0.6567\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 2.7035 - val_accuracy: 0.6511\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 2.2255 - val_accuracy: 0.6494\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 2.4041 - val_accuracy: 0.6522\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 2.5110 - val_accuracy: 0.6544\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 2.5367 - val_accuracy: 0.6522\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 2.5875 - val_accuracy: 0.6494\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 2.8302 - val_accuracy: 0.6650\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 2.7909 - val_accuracy: 0.6522\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 2.7341 - val_accuracy: 0.6500\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 2.7529 - val_accuracy: 0.6606\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 2.6350 - val_accuracy: 0.6672\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 2.3218 - val_accuracy: 0.6617\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 2.3352 - val_accuracy: 0.6583\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 2.6086 - val_accuracy: 0.6561\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.7380 - val_accuracy: 0.6556\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 2.7619 - val_accuracy: 0.6606\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 2.4283 - val_accuracy: 0.6533\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 2.5343 - val_accuracy: 0.6417\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 2.7605 - val_accuracy: 0.6472\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 2.7929 - val_accuracy: 0.6517\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 2.8372 - val_accuracy: 0.6511\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 2.8848 - val_accuracy: 0.6439\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 2.7682 - val_accuracy: 0.6589\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 2.5247 - val_accuracy: 0.6528\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 2.5778 - val_accuracy: 0.6522\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 2.6976 - val_accuracy: 0.6483\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 2.6963 - val_accuracy: 0.6450\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 2.7253 - val_accuracy: 0.6494\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.8235 - val_accuracy: 0.6533\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.9844 - val_accuracy: 0.6500\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.1236 - val_accuracy: 0.6522\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 3.0428 - val_accuracy: 0.6500\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 3.0846 - val_accuracy: 0.6406\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 2.9243 - val_accuracy: 0.6533\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 2.4996 - val_accuracy: 0.6494\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 2.3449 - val_accuracy: 0.6517\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 2.5536 - val_accuracy: 0.6644\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.7622 - val_accuracy: 0.6478\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 2.8758 - val_accuracy: 0.6433\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 2.9737 - val_accuracy: 0.6328\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 2.4640 - val_accuracy: 0.6539\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 2.5288 - val_accuracy: 0.6483\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 2.7071 - val_accuracy: 0.6556\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 2.6330 - val_accuracy: 0.6394\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 2.7813 - val_accuracy: 0.6478\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 2.8518 - val_accuracy: 0.6544\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 2.9576 - val_accuracy: 0.6572\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 3.0472 - val_accuracy: 0.6500\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 3.0359 - val_accuracy: 0.6483\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 2.6681 - val_accuracy: 0.6367\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 2.7970 - val_accuracy: 0.6606\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 2.9624 - val_accuracy: 0.6461\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 3.0465 - val_accuracy: 0.6478\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 3.1542 - val_accuracy: 0.6406\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 3.1337 - val_accuracy: 0.6450\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 2.7961 - val_accuracy: 0.6389\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 2.8133 - val_accuracy: 0.6428\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 2.7762 - val_accuracy: 0.6461\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 2.8197 - val_accuracy: 0.6406\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 2.9327 - val_accuracy: 0.6583\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 3.1729 - val_accuracy: 0.6311\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 3.1329 - val_accuracy: 0.6389\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 2.8259 - val_accuracy: 0.6361\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 2.8259 - val_accuracy: 0.6378\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 2.6552 - val_accuracy: 0.6389\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 2.7608 - val_accuracy: 0.6394\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 3.0129 - val_accuracy: 0.6489\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 3.0691 - val_accuracy: 0.6483\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 3.0747 - val_accuracy: 0.6461\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 3.1293 - val_accuracy: 0.6467\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 3.1856 - val_accuracy: 0.6511\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 2.7516 - val_accuracy: 0.6461\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 2.8005 - val_accuracy: 0.6406\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 2.9593 - val_accuracy: 0.6461\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.0292 - val_accuracy: 0.6456\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 3.0766 - val_accuracy: 0.6483\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 2.9913 - val_accuracy: 0.6422\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 3.1040 - val_accuracy: 0.6494\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 3.1462 - val_accuracy: 0.6428\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 3.0806 - val_accuracy: 0.6422\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.9483 - val_accuracy: 0.6500\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 3.0398 - val_accuracy: 0.6306\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 2.5158 - val_accuracy: 0.6472\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 2.6027 - val_accuracy: 0.6506\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 2.9310 - val_accuracy: 0.6461\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 2.8952 - val_accuracy: 0.6550\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 2.8441 - val_accuracy: 0.6522\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 3.1168 - val_accuracy: 0.6583\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 3.0549 - val_accuracy: 0.6539\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 3.0082 - val_accuracy: 0.6589\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 2.9086 - val_accuracy: 0.6478\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 3.0189 - val_accuracy: 0.6428\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 2.7528 - val_accuracy: 0.6500\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 2.8236 - val_accuracy: 0.6411\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 2.7941 - val_accuracy: 0.6589\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 3.0499 - val_accuracy: 0.6478\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 2.9254 - val_accuracy: 0.6517\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 3.0342 - val_accuracy: 0.6583\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 3.0483 - val_accuracy: 0.6550\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 3.0775 - val_accuracy: 0.6594\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 3.1139 - val_accuracy: 0.6572\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9978 - val_loss: 3.1490 - val_accuracy: 0.6394\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 3.1544 - val_accuracy: 0.6550\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 3.2310 - val_accuracy: 0.6500\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 4.9373e-04 - accuracy: 0.9999 - val_loss: 3.2995 - val_accuracy: 0.6417\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.3843e-04 - accuracy: 1.0000 - val_loss: 3.3794 - val_accuracy: 0.6533\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 4.3269e-05 - accuracy: 1.0000 - val_loss: 3.4323 - val_accuracy: 0.6483\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 3.5734e-05 - accuracy: 1.0000 - val_loss: 3.4564 - val_accuracy: 0.6494\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 2.7209e-05 - accuracy: 1.0000 - val_loss: 3.4827 - val_accuracy: 0.6494\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 2.5543e-05 - accuracy: 1.0000 - val_loss: 3.5062 - val_accuracy: 0.6489\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 2.1587e-05 - accuracy: 1.0000 - val_loss: 3.5280 - val_accuracy: 0.6494\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.9945e-05 - accuracy: 1.0000 - val_loss: 3.5480 - val_accuracy: 0.6500\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.8599e-05 - accuracy: 1.0000 - val_loss: 3.5671 - val_accuracy: 0.6506\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.6512e-05 - accuracy: 1.0000 - val_loss: 3.5851 - val_accuracy: 0.6500\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.5124e-05 - accuracy: 1.0000 - val_loss: 3.6022 - val_accuracy: 0.6500\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.4819e-05 - accuracy: 1.0000 - val_loss: 3.6185 - val_accuracy: 0.6506\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.3657e-05 - accuracy: 1.0000 - val_loss: 3.6340 - val_accuracy: 0.6517\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.2972e-05 - accuracy: 1.0000 - val_loss: 3.6489 - val_accuracy: 0.6517\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1242e-05 - accuracy: 1.0000 - val_loss: 3.6634 - val_accuracy: 0.6522\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0997e-05 - accuracy: 1.0000 - val_loss: 3.6772 - val_accuracy: 0.6522\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 9.8700e-06 - accuracy: 1.0000 - val_loss: 3.6901 - val_accuracy: 0.6528\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 9.8599e-06 - accuracy: 1.0000 - val_loss: 3.7032 - val_accuracy: 0.6522\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 9.0047e-06 - accuracy: 1.0000 - val_loss: 3.7157 - val_accuracy: 0.6528\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 8.5883e-06 - accuracy: 1.0000 - val_loss: 3.7278 - val_accuracy: 0.6528\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 8.5846e-06 - accuracy: 1.0000 - val_loss: 3.7398 - val_accuracy: 0.6528\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 8.2164e-06 - accuracy: 1.0000 - val_loss: 3.7517 - val_accuracy: 0.6539\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 7.7570e-06 - accuracy: 1.0000 - val_loss: 3.7629 - val_accuracy: 0.6539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT0kpwL072No"
      },
      "source": [
        "## Plot the training and validation losses\n",
        "\n",
        "Let's build a function to help us generate clean plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DBrKlpg2duG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plotter(history_dict):\n",
        "  \"\"\"\n",
        "  Plots loss, val_loss of multiple models on the same graph.\n",
        "\n",
        "  Input:\n",
        "   - history_dict: dictionary of model names (keys) and history objects (values)\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.xscale('log')\n",
        "  #plt.xlim([5, max(plt.xlim())])\n",
        "  plt.ylim([0.5, 0.7])\n",
        "  plt.grid(True)\n",
        "  for model_name in history_dict.keys(): # loop over the passed model names\n",
        "    history = history_dict[model_name] # get history variable from the dictionary\n",
        "    plt.plot(history.history['loss'],\n",
        "             linestyle='-', # solid line\n",
        "             label = model_name + ' Train')\n",
        "    plt.plot(history.history['val_loss'],\n",
        "             linestyle='--', # dashed line\n",
        "             label = model_name + ' Val')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "\n",
        "  plt.legend(loc='lower left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSTbkvsZ-wB4"
      },
      "source": [
        "Now, let's compare the learning curves of our four models. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "m8VUqCtC-0A5",
        "outputId": "cdf5ce65-37ab-4af5-cedf-07fc5490b0ec"
      },
      "source": [
        "plotter(model_histories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PsEdLZgaDyT"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV0p4_yBaF92",
        "outputId": "1abcc698-669a-421b-c9eb-0c8aacf09e65"
      },
      "source": [
        "tiny_loss, tiny_acc = tiny_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.5990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqY8jjYzPUgS",
        "outputId": "6465b233-ae21-4ede-8ef8-e2b975e20216"
      },
      "source": [
        "small_loss, small_acc = small_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.7887 - accuracy: 0.5340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYKfKUGVPYuF",
        "outputId": "f169f596-5e02-4fa6-a1a8-40d7efd44630"
      },
      "source": [
        "medium_loss, medium_acc = medium_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 2.2232 - accuracy: 0.5295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aoiZXW9PalG",
        "outputId": "76e59cbb-211d-4b28-eddd-aab43b10ba24"
      },
      "source": [
        "large_loss, large_acc = large_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 4.3190 - accuracy: 0.5355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwWNwsd3Pw9n"
      },
      "source": [
        "# Preventing Overfitting\n",
        "\n",
        "As we have seen, overfitting happens when the model is too complex for the data. That is, when a simpler model exists that can accurately model the data, the more complex model is likely to overfit to the training samples.\n",
        "\n",
        "To prevent this from happening, we can apply one or more regularization techniques. **Regularization** refers to modifications to the learning algorithm such that the model generalizes better. The idea is to penalize complexity so the model is forced to learn the simplest possible representation of the training data.\n",
        "\n",
        "Multiple regularization techniques exist, such as:\n",
        "1. Weight regularization\n",
        "    1. L1\n",
        "    2. L2\n",
        "2. Dropout\n",
        "3. Early stopping\n",
        "4. Data augmentation\n",
        "5. Noise injection\n",
        "\n",
        "In this lab, we will explore the first three."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9fzCoUbS6Ue"
      },
      "source": [
        "## Weight Regularization\n",
        "\n",
        "One way to penalize complexity is to penalize large weights. This is done by adding all our parameters (weights) to our loss function. The new loss function thus becomes\n",
        "\n",
        "$ J(w) + \\frac{\\lambda}{2} \\sum_{j=1}^{M}\\left|w_{j}\\right|^{q}$\n",
        "\n",
        ">- When $q=1$, we call it **L1 regularization** (we are adding what is called the \"L1 norm\" of the weights).\n",
        "- When $q=2$, we call it **L2 regularization** (we are adding what is called the \"L2 norm\" of the weights).\n",
        "- (Q) What happens when the parameter $\\lambda$ is increased?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-xenhlRaPm5"
      },
      "source": [
        "regularizer_histories = {} # new dictioanry to store regularized model histories\n",
        "regularizer_histories['Tiny'] = model_histories['Tiny']\n",
        "regularizer_histories['Large'] = model_histories['Large']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqfUn2sMXQoW",
        "outputId": "a30e75b7-09d8-4a69-a924-d98ef3369c1e"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "l2_lambda = 0.01\n",
        "l2_model = Sequential([\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = l2(l2_lambda),\n",
        "                 input_shape = (FEATURES,)),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = l2(l2_lambda)),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = l2(l2_lambda)),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = l2(l2_lambda)),\n",
        "    Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "regularizer_histories['l2'] = compile_and_fit(l2_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 803,329\n",
            "Trainable params: 803,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 12.5335 - accuracy: 0.5508 - val_loss: 4.2186 - val_accuracy: 0.6317\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 3.1169 - accuracy: 0.6168 - val_loss: 1.1967 - val_accuracy: 0.6678\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0147 - accuracy: 0.6435 - val_loss: 0.7253 - val_accuracy: 0.6561\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.6615 - val_loss: 0.6735 - val_accuracy: 0.6439\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.6528 - val_loss: 0.6562 - val_accuracy: 0.6794\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.6672 - val_loss: 0.6571 - val_accuracy: 0.6844\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6719 - val_loss: 0.6549 - val_accuracy: 0.6822\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6710 - val_loss: 0.6504 - val_accuracy: 0.6856\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.6809 - val_loss: 0.6523 - val_accuracy: 0.6656\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6757 - val_loss: 0.6495 - val_accuracy: 0.6628\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6743 - val_loss: 0.6495 - val_accuracy: 0.6800\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6767 - val_loss: 0.6441 - val_accuracy: 0.6844\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6764 - val_loss: 0.6459 - val_accuracy: 0.6861\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6891 - val_loss: 0.6465 - val_accuracy: 0.6778\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.6845 - val_loss: 0.6508 - val_accuracy: 0.6550\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6830 - val_loss: 0.6480 - val_accuracy: 0.6772\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6922 - val_loss: 0.6468 - val_accuracy: 0.6906\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6862 - val_loss: 0.6477 - val_accuracy: 0.6817\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6917 - val_loss: 0.6431 - val_accuracy: 0.6911\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6929 - val_loss: 0.6427 - val_accuracy: 0.6889\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6876 - val_loss: 0.6441 - val_accuracy: 0.6878\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.6977 - val_loss: 0.6451 - val_accuracy: 0.6861\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.6933 - val_loss: 0.6414 - val_accuracy: 0.6883\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6965 - val_loss: 0.6458 - val_accuracy: 0.6828\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6958 - val_loss: 0.6444 - val_accuracy: 0.6900\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.6981 - val_loss: 0.6447 - val_accuracy: 0.6711\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.6989 - val_loss: 0.6411 - val_accuracy: 0.7033\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7042 - val_loss: 0.6495 - val_accuracy: 0.6861\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6962 - val_loss: 0.6465 - val_accuracy: 0.6878\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7046 - val_loss: 0.6457 - val_accuracy: 0.6961\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.7077 - val_loss: 0.6476 - val_accuracy: 0.6811\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7091 - val_loss: 0.6429 - val_accuracy: 0.6906\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7047 - val_loss: 0.6437 - val_accuracy: 0.6944\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7049 - val_loss: 0.6397 - val_accuracy: 0.6883\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.7063 - val_loss: 0.6544 - val_accuracy: 0.6939\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.7100 - val_loss: 0.6406 - val_accuracy: 0.6850\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7066 - val_loss: 0.6471 - val_accuracy: 0.6856\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.7070 - val_loss: 0.6401 - val_accuracy: 0.6922\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7162 - val_loss: 0.6422 - val_accuracy: 0.6989\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.7112 - val_loss: 0.6428 - val_accuracy: 0.6950\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.7108 - val_loss: 0.6432 - val_accuracy: 0.6872\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.7116 - val_loss: 0.6408 - val_accuracy: 0.6850\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7080 - val_loss: 0.6394 - val_accuracy: 0.6917\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.7122 - val_loss: 0.6391 - val_accuracy: 0.6922\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7054 - val_loss: 0.6415 - val_accuracy: 0.6856\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7126 - val_loss: 0.6438 - val_accuracy: 0.6861\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.7114 - val_loss: 0.6407 - val_accuracy: 0.6867\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.7151 - val_loss: 0.6412 - val_accuracy: 0.6867\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.7213 - val_loss: 0.6468 - val_accuracy: 0.6844\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7189 - val_loss: 0.6462 - val_accuracy: 0.6867\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7209 - val_loss: 0.6618 - val_accuracy: 0.6839\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7142 - val_loss: 0.6432 - val_accuracy: 0.6939\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7204 - val_loss: 0.6373 - val_accuracy: 0.6994\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7221 - val_loss: 0.6471 - val_accuracy: 0.6889\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7232 - val_loss: 0.6417 - val_accuracy: 0.6889\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.7198 - val_loss: 0.6460 - val_accuracy: 0.6922\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.7195 - val_loss: 0.6415 - val_accuracy: 0.6939\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.7202 - val_loss: 0.6408 - val_accuracy: 0.6989\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7254 - val_loss: 0.6385 - val_accuracy: 0.6983\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.7251 - val_loss: 0.6421 - val_accuracy: 0.6889\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.7222 - val_loss: 0.6507 - val_accuracy: 0.6967\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7238 - val_loss: 0.6430 - val_accuracy: 0.6950\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.7242 - val_loss: 0.6387 - val_accuracy: 0.6900\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.7225 - val_loss: 0.6448 - val_accuracy: 0.6933\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7298 - val_loss: 0.6432 - val_accuracy: 0.6978\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.7262 - val_loss: 0.6393 - val_accuracy: 0.6978\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5999 - accuracy: 0.7266 - val_loss: 0.6422 - val_accuracy: 0.6950\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.7228 - val_loss: 0.6404 - val_accuracy: 0.6928\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7237 - val_loss: 0.6419 - val_accuracy: 0.6922\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.7277 - val_loss: 0.6495 - val_accuracy: 0.6978\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7304 - val_loss: 0.6846 - val_accuracy: 0.6728\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7245 - val_loss: 0.6497 - val_accuracy: 0.6956\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7308 - val_loss: 0.6417 - val_accuracy: 0.6967\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7286 - val_loss: 0.6444 - val_accuracy: 0.6939\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.7337 - val_loss: 0.6507 - val_accuracy: 0.6711\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.7284 - val_loss: 0.6430 - val_accuracy: 0.6928\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.7218 - val_loss: 0.6617 - val_accuracy: 0.6883\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5958 - accuracy: 0.7289 - val_loss: 0.6423 - val_accuracy: 0.6950\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7308 - val_loss: 0.6448 - val_accuracy: 0.7033\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6003 - accuracy: 0.7297 - val_loss: 0.6472 - val_accuracy: 0.6894\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.7320 - val_loss: 0.6409 - val_accuracy: 0.7061\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.7384 - val_loss: 0.6544 - val_accuracy: 0.6978\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5905 - accuracy: 0.7356 - val_loss: 0.6445 - val_accuracy: 0.6917\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7317 - val_loss: 0.6524 - val_accuracy: 0.6944\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7364 - val_loss: 0.6453 - val_accuracy: 0.6850\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7327 - val_loss: 0.6476 - val_accuracy: 0.6961\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.7324 - val_loss: 0.6597 - val_accuracy: 0.6989\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.7291 - val_loss: 0.6482 - val_accuracy: 0.6956\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7370 - val_loss: 0.6421 - val_accuracy: 0.7028\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7431 - val_loss: 0.6453 - val_accuracy: 0.6922\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7305 - val_loss: 0.6554 - val_accuracy: 0.6944\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7367 - val_loss: 0.6542 - val_accuracy: 0.6928\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7370 - val_loss: 0.6442 - val_accuracy: 0.6883\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.7368 - val_loss: 0.6435 - val_accuracy: 0.6928\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.7277 - val_loss: 0.6441 - val_accuracy: 0.7033\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7440 - val_loss: 0.6438 - val_accuracy: 0.7006\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7339 - val_loss: 0.6515 - val_accuracy: 0.7039\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.7359 - val_loss: 0.6451 - val_accuracy: 0.6978\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7396 - val_loss: 0.6466 - val_accuracy: 0.7017\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7340 - val_loss: 0.6480 - val_accuracy: 0.6872\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7378 - val_loss: 0.6451 - val_accuracy: 0.7067\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5850 - accuracy: 0.7402 - val_loss: 0.6475 - val_accuracy: 0.7044\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.7401 - val_loss: 0.6464 - val_accuracy: 0.7033\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.7359 - val_loss: 0.6437 - val_accuracy: 0.7033\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7422 - val_loss: 0.6414 - val_accuracy: 0.6983\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.7461 - val_loss: 0.6439 - val_accuracy: 0.7100\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7428 - val_loss: 0.6453 - val_accuracy: 0.7144\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7421 - val_loss: 0.6508 - val_accuracy: 0.6817\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7459 - val_loss: 0.6418 - val_accuracy: 0.6944\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.7381 - val_loss: 0.6493 - val_accuracy: 0.7039\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.7424 - val_loss: 0.6491 - val_accuracy: 0.7050\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.7346 - val_loss: 0.6431 - val_accuracy: 0.7083\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7508 - val_loss: 0.6392 - val_accuracy: 0.7022\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7498 - val_loss: 0.6486 - val_accuracy: 0.7078\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5850 - accuracy: 0.7381 - val_loss: 0.6469 - val_accuracy: 0.6978\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.7499 - val_loss: 0.6505 - val_accuracy: 0.7089\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7482 - val_loss: 0.6466 - val_accuracy: 0.6994\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7483 - val_loss: 0.6485 - val_accuracy: 0.6989\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7501 - val_loss: 0.6462 - val_accuracy: 0.7011\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7473 - val_loss: 0.6516 - val_accuracy: 0.6967\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.7504 - val_loss: 0.6530 - val_accuracy: 0.6922\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5783 - accuracy: 0.7456 - val_loss: 0.6574 - val_accuracy: 0.7061\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7523 - val_loss: 0.6740 - val_accuracy: 0.6800\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7459 - val_loss: 0.6460 - val_accuracy: 0.7000\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.7482 - val_loss: 0.6563 - val_accuracy: 0.7022\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7535 - val_loss: 0.6475 - val_accuracy: 0.6900\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7529 - val_loss: 0.6697 - val_accuracy: 0.6856\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5735 - accuracy: 0.7524 - val_loss: 0.6467 - val_accuracy: 0.7028\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.7517 - val_loss: 0.6535 - val_accuracy: 0.6989\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7561 - val_loss: 0.6513 - val_accuracy: 0.7006\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.7491 - val_loss: 0.6649 - val_accuracy: 0.6961\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.7491 - val_loss: 0.6527 - val_accuracy: 0.7033\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7541 - val_loss: 0.6596 - val_accuracy: 0.6778\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7512 - val_loss: 0.6554 - val_accuracy: 0.7000\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.7494 - val_loss: 0.6442 - val_accuracy: 0.7000\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.7527 - val_loss: 0.6621 - val_accuracy: 0.6900\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7493 - val_loss: 0.6587 - val_accuracy: 0.7022\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7523 - val_loss: 0.6999 - val_accuracy: 0.6750\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.7496 - val_loss: 0.6661 - val_accuracy: 0.6872\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.7465 - val_loss: 0.6627 - val_accuracy: 0.6956\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7553 - val_loss: 0.6626 - val_accuracy: 0.6961\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.7530 - val_loss: 0.6672 - val_accuracy: 0.6928\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7560 - val_loss: 0.6644 - val_accuracy: 0.7000\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7563 - val_loss: 0.6553 - val_accuracy: 0.7011\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7556 - val_loss: 0.6538 - val_accuracy: 0.6978\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7560 - val_loss: 0.6545 - val_accuracy: 0.6911\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7594 - val_loss: 0.6600 - val_accuracy: 0.7000\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7599 - val_loss: 0.6521 - val_accuracy: 0.6939\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.7612 - val_loss: 0.6621 - val_accuracy: 0.6906\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7629 - val_loss: 0.6673 - val_accuracy: 0.6933\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.7504 - val_loss: 0.6519 - val_accuracy: 0.6994\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7581 - val_loss: 0.6759 - val_accuracy: 0.6822\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5729 - accuracy: 0.7530 - val_loss: 0.6577 - val_accuracy: 0.6989\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7601 - val_loss: 0.6746 - val_accuracy: 0.6817\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7609 - val_loss: 0.6645 - val_accuracy: 0.6939\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7636 - val_loss: 0.6625 - val_accuracy: 0.6933\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7611 - val_loss: 0.6580 - val_accuracy: 0.6950\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7651 - val_loss: 0.6632 - val_accuracy: 0.6994\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7598 - val_loss: 0.6635 - val_accuracy: 0.6917\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7685 - val_loss: 0.6675 - val_accuracy: 0.6944\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.7535 - val_loss: 0.6679 - val_accuracy: 0.6989\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7640 - val_loss: 0.6612 - val_accuracy: 0.6933\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7590 - val_loss: 0.6943 - val_accuracy: 0.6794\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7518 - val_loss: 0.6816 - val_accuracy: 0.6811\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7538 - val_loss: 0.6627 - val_accuracy: 0.6928\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7716 - val_loss: 0.6701 - val_accuracy: 0.6883\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5632 - accuracy: 0.7610 - val_loss: 0.6657 - val_accuracy: 0.6900\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7658 - val_loss: 0.7060 - val_accuracy: 0.6844\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7536 - val_loss: 0.6629 - val_accuracy: 0.6950\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7608 - val_loss: 0.6627 - val_accuracy: 0.7011\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7685 - val_loss: 0.6684 - val_accuracy: 0.7089\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7659 - val_loss: 0.6703 - val_accuracy: 0.6889\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7654 - val_loss: 0.6726 - val_accuracy: 0.6939\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7633 - val_loss: 0.6713 - val_accuracy: 0.6950\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7681 - val_loss: 0.6738 - val_accuracy: 0.6944\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7660 - val_loss: 0.6745 - val_accuracy: 0.6950\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7753 - val_loss: 0.6731 - val_accuracy: 0.6983\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7682 - val_loss: 0.6706 - val_accuracy: 0.6883\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7672 - val_loss: 0.6751 - val_accuracy: 0.6894\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.7700 - val_loss: 0.6806 - val_accuracy: 0.6911\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.7634 - val_loss: 0.6658 - val_accuracy: 0.6994\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7700 - val_loss: 0.6731 - val_accuracy: 0.6944\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7616 - val_loss: 0.6747 - val_accuracy: 0.6917\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7660 - val_loss: 0.6756 - val_accuracy: 0.6889\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7696 - val_loss: 0.6665 - val_accuracy: 0.6883\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7692 - val_loss: 0.6709 - val_accuracy: 0.6878\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7677 - val_loss: 0.6747 - val_accuracy: 0.6922\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.7709 - val_loss: 0.6701 - val_accuracy: 0.6956\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.7660 - val_loss: 0.6772 - val_accuracy: 0.6850\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.7664 - val_loss: 0.6691 - val_accuracy: 0.6928\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7678 - val_loss: 0.6687 - val_accuracy: 0.6967\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7724 - val_loss: 0.6742 - val_accuracy: 0.6972\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7694 - val_loss: 0.6855 - val_accuracy: 0.6806\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7599 - val_loss: 0.6699 - val_accuracy: 0.6928\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7716 - val_loss: 0.6707 - val_accuracy: 0.6822\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7655 - val_loss: 0.6825 - val_accuracy: 0.6872\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7668 - val_loss: 0.6776 - val_accuracy: 0.6883\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7716 - val_loss: 0.6722 - val_accuracy: 0.6928\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7727 - val_loss: 0.6795 - val_accuracy: 0.6922\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7688 - val_loss: 0.6786 - val_accuracy: 0.6894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwyY0U8bS9BF"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fh1gYwHbizF"
      },
      "source": [
        "The intuitive explanation for dropout is that we need to force each node to output features that are useful on their own.\n",
        "\n",
        "Dropout involves randomly \"dropping out\" (i.e. setting to zero) a number of output features of a layer during training. Let's say a given layer would normally have returned a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. [0, 0.5, 1.3, 0, 1.1].\n",
        "\n",
        "The \"dropout rate\" is a hyperparameter specifying the fraction of features that are being zeroed-out; it is usually set between 0.2 and 0.5.\n",
        "\n",
        "<center><img src=\"http://cs231n.github.io/assets/nn2/dropout.jpeg\"\n",
        " width=\"400px\"> </center>\n",
        "\n",
        "Note that at test time, no units are dropped out, and instead the layer's output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_rEjs8FbXHt",
        "outputId": "28a24ef6-01ae-48cb-bd83-39384c50c119"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "dropout_rate = 0.5\n",
        "\n",
        "dropout_model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(FEATURES,)),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "model_histories['dropout'] = compile_and_fit(dropout_model, max_epochs = EPOCHS)\n",
        "regularizer_histories['dropout'] = model_histories['dropout']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 803,329\n",
            "Trainable params: 803,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 0.7004 - accuracy: 0.5264 - val_loss: 0.6570 - val_accuracy: 0.6228\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.5867 - val_loss: 0.6388 - val_accuracy: 0.6444\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6211 - val_loss: 0.6304 - val_accuracy: 0.6517\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6336 - val_loss: 0.6264 - val_accuracy: 0.6778\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6465 - val_loss: 0.6246 - val_accuracy: 0.6783\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.6544 - val_loss: 0.6205 - val_accuracy: 0.6756\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6623 - val_loss: 0.6192 - val_accuracy: 0.6822\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.6647 - val_loss: 0.6110 - val_accuracy: 0.6839\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6658 - val_loss: 0.6110 - val_accuracy: 0.6872\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6654 - val_loss: 0.6109 - val_accuracy: 0.6889\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5992 - accuracy: 0.6776 - val_loss: 0.6060 - val_accuracy: 0.6872\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.6811 - val_loss: 0.6003 - val_accuracy: 0.6811\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.6782 - val_loss: 0.6044 - val_accuracy: 0.6894\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5916 - accuracy: 0.6891 - val_loss: 0.5984 - val_accuracy: 0.6883\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.6845 - val_loss: 0.5952 - val_accuracy: 0.6917\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.6955 - val_loss: 0.5954 - val_accuracy: 0.6872\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.6968 - val_loss: 0.5938 - val_accuracy: 0.6933\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.6963 - val_loss: 0.5940 - val_accuracy: 0.6900\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.7024 - val_loss: 0.5953 - val_accuracy: 0.6872\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.6977 - val_loss: 0.5889 - val_accuracy: 0.6894\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5679 - accuracy: 0.6960 - val_loss: 0.5906 - val_accuracy: 0.6800\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7093 - val_loss: 0.5878 - val_accuracy: 0.6922\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7053 - val_loss: 0.5937 - val_accuracy: 0.6917\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5609 - accuracy: 0.7045 - val_loss: 0.5874 - val_accuracy: 0.6894\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.7106 - val_loss: 0.5832 - val_accuracy: 0.6961\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7082 - val_loss: 0.5813 - val_accuracy: 0.6950\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.7206 - val_loss: 0.5827 - val_accuracy: 0.6922\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7217 - val_loss: 0.5812 - val_accuracy: 0.6978\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7176 - val_loss: 0.5881 - val_accuracy: 0.6917\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7232 - val_loss: 0.5842 - val_accuracy: 0.6928\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7157 - val_loss: 0.5923 - val_accuracy: 0.6967\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7258 - val_loss: 0.5812 - val_accuracy: 0.6917\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7256 - val_loss: 0.5865 - val_accuracy: 0.6956\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7323 - val_loss: 0.5842 - val_accuracy: 0.6911\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.7286 - val_loss: 0.5857 - val_accuracy: 0.6978\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7307 - val_loss: 0.5830 - val_accuracy: 0.6972\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.7304 - val_loss: 0.5871 - val_accuracy: 0.6889\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7366 - val_loss: 0.5916 - val_accuracy: 0.6894\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7365 - val_loss: 0.5871 - val_accuracy: 0.6950\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7368 - val_loss: 0.5895 - val_accuracy: 0.6933\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7369 - val_loss: 0.5934 - val_accuracy: 0.6883\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7435 - val_loss: 0.5855 - val_accuracy: 0.6933\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7370 - val_loss: 0.5874 - val_accuracy: 0.6950\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7350 - val_loss: 0.5923 - val_accuracy: 0.6917\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7425 - val_loss: 0.5874 - val_accuracy: 0.6989\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7472 - val_loss: 0.5901 - val_accuracy: 0.6900\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7456 - val_loss: 0.5911 - val_accuracy: 0.6956\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7450 - val_loss: 0.5887 - val_accuracy: 0.6894\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7482 - val_loss: 0.5981 - val_accuracy: 0.6889\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7462 - val_loss: 0.5854 - val_accuracy: 0.6939\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7508 - val_loss: 0.5961 - val_accuracy: 0.6961\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7485 - val_loss: 0.5965 - val_accuracy: 0.6939\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7527 - val_loss: 0.5916 - val_accuracy: 0.6961\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7547 - val_loss: 0.5974 - val_accuracy: 0.6933\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7570 - val_loss: 0.5961 - val_accuracy: 0.6872\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7644 - val_loss: 0.5976 - val_accuracy: 0.6917\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7629 - val_loss: 0.6013 - val_accuracy: 0.6894\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7634 - val_loss: 0.5945 - val_accuracy: 0.6944\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7605 - val_loss: 0.6072 - val_accuracy: 0.6939\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7574 - val_loss: 0.5989 - val_accuracy: 0.6844\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7614 - val_loss: 0.6047 - val_accuracy: 0.6933\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7703 - val_loss: 0.5974 - val_accuracy: 0.6944\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7586 - val_loss: 0.6038 - val_accuracy: 0.6911\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7688 - val_loss: 0.6035 - val_accuracy: 0.6917\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7653 - val_loss: 0.5945 - val_accuracy: 0.6978\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7685 - val_loss: 0.5962 - val_accuracy: 0.6939\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7657 - val_loss: 0.6045 - val_accuracy: 0.6911\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.7679 - val_loss: 0.6150 - val_accuracy: 0.6911\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7695 - val_loss: 0.6131 - val_accuracy: 0.6872\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.6179 - val_accuracy: 0.6889\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7712 - val_loss: 0.6121 - val_accuracy: 0.6972\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7813 - val_loss: 0.6104 - val_accuracy: 0.6978\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7731 - val_loss: 0.6070 - val_accuracy: 0.6939\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7757 - val_loss: 0.6217 - val_accuracy: 0.6856\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.6149 - val_accuracy: 0.6944\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7799 - val_loss: 0.6179 - val_accuracy: 0.6939\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7803 - val_loss: 0.6102 - val_accuracy: 0.6961\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7824 - val_loss: 0.6227 - val_accuracy: 0.6989\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7872 - val_loss: 0.6259 - val_accuracy: 0.6978\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7768 - val_loss: 0.6052 - val_accuracy: 0.6911\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7832 - val_loss: 0.6150 - val_accuracy: 0.6900\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7892 - val_loss: 0.6205 - val_accuracy: 0.6872\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7954 - val_loss: 0.6262 - val_accuracy: 0.6911\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7894 - val_loss: 0.6158 - val_accuracy: 0.6883\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7918 - val_loss: 0.6160 - val_accuracy: 0.6978\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7953 - val_loss: 0.6240 - val_accuracy: 0.6900\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7994 - val_loss: 0.6236 - val_accuracy: 0.6956\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7891 - val_loss: 0.6285 - val_accuracy: 0.6889\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7869 - val_loss: 0.6360 - val_accuracy: 0.6922\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7945 - val_loss: 0.6394 - val_accuracy: 0.6933\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7975 - val_loss: 0.6363 - val_accuracy: 0.6917\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7953 - val_loss: 0.6436 - val_accuracy: 0.6872\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7960 - val_loss: 0.6338 - val_accuracy: 0.6861\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8037 - val_loss: 0.6420 - val_accuracy: 0.6950\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8001 - val_loss: 0.6399 - val_accuracy: 0.6817\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8068 - val_loss: 0.6416 - val_accuracy: 0.6828\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8038 - val_loss: 0.6359 - val_accuracy: 0.6933\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8034 - val_loss: 0.6453 - val_accuracy: 0.6889\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8030 - val_loss: 0.6409 - val_accuracy: 0.6878\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8001 - val_loss: 0.6524 - val_accuracy: 0.6867\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8138 - val_loss: 0.6503 - val_accuracy: 0.6894\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8077 - val_loss: 0.6408 - val_accuracy: 0.6844\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8114 - val_loss: 0.6372 - val_accuracy: 0.6828\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8086 - val_loss: 0.6379 - val_accuracy: 0.6894\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8072 - val_loss: 0.6496 - val_accuracy: 0.6878\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8095 - val_loss: 0.6550 - val_accuracy: 0.6911\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8024 - val_loss: 0.6671 - val_accuracy: 0.6933\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8192 - val_loss: 0.6515 - val_accuracy: 0.6844\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8120 - val_loss: 0.6586 - val_accuracy: 0.6806\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8132 - val_loss: 0.6559 - val_accuracy: 0.6761\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8225 - val_loss: 0.6499 - val_accuracy: 0.6867\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8141 - val_loss: 0.6517 - val_accuracy: 0.6828\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8153 - val_loss: 0.6497 - val_accuracy: 0.6739\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8143 - val_loss: 0.6585 - val_accuracy: 0.6789\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8202 - val_loss: 0.6648 - val_accuracy: 0.6833\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8236 - val_loss: 0.6545 - val_accuracy: 0.6811\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8114 - val_loss: 0.6502 - val_accuracy: 0.6822\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8128 - val_loss: 0.6589 - val_accuracy: 0.6811\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8208 - val_loss: 0.6556 - val_accuracy: 0.6922\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8244 - val_loss: 0.6684 - val_accuracy: 0.6794\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8207 - val_loss: 0.6702 - val_accuracy: 0.6772\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8226 - val_loss: 0.6538 - val_accuracy: 0.6800\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8236 - val_loss: 0.6650 - val_accuracy: 0.6839\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8231 - val_loss: 0.6625 - val_accuracy: 0.6783\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8260 - val_loss: 0.6878 - val_accuracy: 0.6811\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8280 - val_loss: 0.6751 - val_accuracy: 0.6867\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8267 - val_loss: 0.6800 - val_accuracy: 0.6789\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8291 - val_loss: 0.6763 - val_accuracy: 0.6806\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8247 - val_loss: 0.6730 - val_accuracy: 0.6789\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8267 - val_loss: 0.6880 - val_accuracy: 0.6772\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8261 - val_loss: 0.6637 - val_accuracy: 0.6833\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8263 - val_loss: 0.6902 - val_accuracy: 0.6822\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8283 - val_loss: 0.6809 - val_accuracy: 0.6839\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8282 - val_loss: 0.6847 - val_accuracy: 0.6800\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8262 - val_loss: 0.7088 - val_accuracy: 0.6833\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8311 - val_loss: 0.6901 - val_accuracy: 0.6828\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8276 - val_loss: 0.6878 - val_accuracy: 0.6772\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8332 - val_loss: 0.6898 - val_accuracy: 0.6733\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8315 - val_loss: 0.7013 - val_accuracy: 0.6828\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8376 - val_loss: 0.6910 - val_accuracy: 0.6778\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8334 - val_loss: 0.6868 - val_accuracy: 0.6756\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8312 - val_loss: 0.6774 - val_accuracy: 0.6806\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8296 - val_loss: 0.6795 - val_accuracy: 0.6800\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8346 - val_loss: 0.6932 - val_accuracy: 0.6794\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8372 - val_loss: 0.6876 - val_accuracy: 0.6767\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8297 - val_loss: 0.6894 - val_accuracy: 0.6789\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8390 - val_loss: 0.6856 - val_accuracy: 0.6811\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8387 - val_loss: 0.6850 - val_accuracy: 0.6789\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8417 - val_loss: 0.6806 - val_accuracy: 0.6806\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8406 - val_loss: 0.6915 - val_accuracy: 0.6828\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8435 - val_loss: 0.6805 - val_accuracy: 0.6800\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8437 - val_loss: 0.6811 - val_accuracy: 0.6828\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8435 - val_loss: 0.6717 - val_accuracy: 0.6833\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8464 - val_loss: 0.6866 - val_accuracy: 0.6928\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8416 - val_loss: 0.6845 - val_accuracy: 0.6844\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8416 - val_loss: 0.7150 - val_accuracy: 0.6756\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8466 - val_loss: 0.6903 - val_accuracy: 0.6828\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8433 - val_loss: 0.7199 - val_accuracy: 0.6833\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8436 - val_loss: 0.7000 - val_accuracy: 0.6800\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8432 - val_loss: 0.7026 - val_accuracy: 0.6939\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8468 - val_loss: 0.6999 - val_accuracy: 0.6856\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8428 - val_loss: 0.6944 - val_accuracy: 0.6878\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8454 - val_loss: 0.7014 - val_accuracy: 0.6861\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8450 - val_loss: 0.6959 - val_accuracy: 0.6817\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8468 - val_loss: 0.6767 - val_accuracy: 0.6861\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8491 - val_loss: 0.7043 - val_accuracy: 0.6806\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8445 - val_loss: 0.7104 - val_accuracy: 0.6856\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8453 - val_loss: 0.6999 - val_accuracy: 0.6828\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8490 - val_loss: 0.7150 - val_accuracy: 0.6878\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8518 - val_loss: 0.7108 - val_accuracy: 0.6856\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8476 - val_loss: 0.7018 - val_accuracy: 0.6867\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8477 - val_loss: 0.6903 - val_accuracy: 0.6883\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8478 - val_loss: 0.7128 - val_accuracy: 0.6850\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8480 - val_loss: 0.7023 - val_accuracy: 0.6911\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8513 - val_loss: 0.7112 - val_accuracy: 0.6822\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8556 - val_loss: 0.6903 - val_accuracy: 0.6839\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8542 - val_loss: 0.6985 - val_accuracy: 0.6817\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8524 - val_loss: 0.7013 - val_accuracy: 0.6889\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8492 - val_loss: 0.6924 - val_accuracy: 0.6889\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8513 - val_loss: 0.7050 - val_accuracy: 0.6828\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8520 - val_loss: 0.7107 - val_accuracy: 0.6822\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8493 - val_loss: 0.7102 - val_accuracy: 0.6822\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8583 - val_loss: 0.7253 - val_accuracy: 0.6794\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8567 - val_loss: 0.7090 - val_accuracy: 0.6839\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8606 - val_loss: 0.7106 - val_accuracy: 0.6828\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8518 - val_loss: 0.7041 - val_accuracy: 0.6817\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8539 - val_loss: 0.7145 - val_accuracy: 0.6883\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8559 - val_loss: 0.7137 - val_accuracy: 0.6767\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8576 - val_loss: 0.7251 - val_accuracy: 0.6828\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8576 - val_loss: 0.7106 - val_accuracy: 0.6783\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8571 - val_loss: 0.7181 - val_accuracy: 0.6833\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8542 - val_loss: 0.7330 - val_accuracy: 0.6806\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3143 - accuracy: 0.8629 - val_loss: 0.7252 - val_accuracy: 0.6717\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8589 - val_loss: 0.7302 - val_accuracy: 0.6750\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8596 - val_loss: 0.7061 - val_accuracy: 0.6789\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8575 - val_loss: 0.7178 - val_accuracy: 0.6767\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8598 - val_loss: 0.7209 - val_accuracy: 0.6794\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8627 - val_loss: 0.7403 - val_accuracy: 0.6750\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8542 - val_loss: 0.7239 - val_accuracy: 0.6822\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8568 - val_loss: 0.7439 - val_accuracy: 0.6744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpFgMYulhU-3"
      },
      "source": [
        "Now, let's plot the learning curves. What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oVgENUhhhNcQ",
        "outputId": "fadf1be2-9167-4f2d-cf4f-ec7f12159b53"
      },
      "source": [
        "plotter(regularizer_histories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcjwERVNHeQR"
      },
      "source": [
        ">(Discussion) Take another look at the loss curves of the dropout model. The model keeps improving until a certain point, after which it starts overfitting, resulting in a poor final model. Suggest one possible solution that can help improve the final model without changing any of its parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fzi3Io2u7jf"
      },
      "source": [
        "# Task\n",
        "\n",
        "Your task is to improve the learning curve even further by applying the following models:\n",
        "1. Model 1: Add both L1 and L2 regularization to the large model. Adjust the parameters to minimize overfitting.\n",
        "1. Model 2: Apply early stopping to the large model with dropout and choose appropriate parameters.\n",
        "1. Plot the losses of each of the new models. Comment on your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bAEK9A3oo67"
      },
      "source": [
        "regularizer_histories = {} # new dictionary to store regularized model histories\n",
        "regularizer_histories['Large'] = model_histories['Large']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPUZpxLRoBx7"
      },
      "source": [
        "## Model 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXJ5jqJaoo7K",
        "outputId": "02cba963-0f6a-4826-8693-4c4a25efebc7"
      },
      "source": [
        "from keras.regularizers import l1_l2\n",
        "\n",
        "regularizer = l1_l2(l1= 0.000075, l2= 0.01)\n",
        "\n",
        "l1_l2_model = Sequential([\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer,\n",
        "                 input_shape = (FEATURES,)),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer),\n",
        "    Dense(512, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer),\n",
        "    Dense(1, activation = \"sigmoid\")\n",
        "])\n",
        "\n",
        "regularizer_histories['l1_l2'] = compile_and_fit(l1_l2_model, max_epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 803,329\n",
            "Trainable params: 803,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 11ms/step - loss: 14.3996 - accuracy: 0.5480 - val_loss: 5.0340 - val_accuracy: 0.5517\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 3.7296 - accuracy: 0.5628 - val_loss: 1.3954 - val_accuracy: 0.5839\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1524 - accuracy: 0.5853 - val_loss: 0.7641 - val_accuracy: 0.6322\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7332 - accuracy: 0.6226 - val_loss: 0.6839 - val_accuracy: 0.6583\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.6411 - val_loss: 0.6714 - val_accuracy: 0.6683\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.6513 - val_loss: 0.6657 - val_accuracy: 0.6611\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.6460 - val_loss: 0.6691 - val_accuracy: 0.6756\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6613 - val_loss: 0.6617 - val_accuracy: 0.6783\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6629 - accuracy: 0.6608 - val_loss: 0.6556 - val_accuracy: 0.6739\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6581 - accuracy: 0.6671 - val_loss: 0.6576 - val_accuracy: 0.6850\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6754 - val_loss: 0.6614 - val_accuracy: 0.6556\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.6638 - val_loss: 0.6581 - val_accuracy: 0.6861\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.6777 - val_loss: 0.6546 - val_accuracy: 0.6822\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6731 - val_loss: 0.6517 - val_accuracy: 0.6789\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6859 - val_loss: 0.6512 - val_accuracy: 0.6939\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6765 - val_loss: 0.6552 - val_accuracy: 0.6889\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6811 - val_loss: 0.6497 - val_accuracy: 0.6783\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6833 - val_loss: 0.6502 - val_accuracy: 0.6878\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6803 - val_loss: 0.6543 - val_accuracy: 0.6939\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6853 - val_loss: 0.6554 - val_accuracy: 0.6850\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6894 - val_loss: 0.6473 - val_accuracy: 0.6917\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.6845 - val_loss: 0.6523 - val_accuracy: 0.6950\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6826 - val_loss: 0.6489 - val_accuracy: 0.6833\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.6915 - val_loss: 0.6521 - val_accuracy: 0.6950\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6923 - val_loss: 0.6495 - val_accuracy: 0.6817\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6924 - val_loss: 0.6504 - val_accuracy: 0.6867\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6899 - val_loss: 0.6496 - val_accuracy: 0.6744\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6943 - val_loss: 0.6457 - val_accuracy: 0.6856\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6945 - val_loss: 0.6550 - val_accuracy: 0.6617\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6841 - val_loss: 0.6448 - val_accuracy: 0.6967\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.6968 - val_loss: 0.6456 - val_accuracy: 0.6994\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6938 - val_loss: 0.6424 - val_accuracy: 0.6994\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6299 - accuracy: 0.6996 - val_loss: 0.6423 - val_accuracy: 0.6972\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6973 - val_loss: 0.6462 - val_accuracy: 0.6883\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.6962 - val_loss: 0.6447 - val_accuracy: 0.6917\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.6944 - val_loss: 0.6420 - val_accuracy: 0.6972\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.6998 - val_loss: 0.6465 - val_accuracy: 0.6989\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7018 - val_loss: 0.6454 - val_accuracy: 0.6911\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.6987 - val_loss: 0.6442 - val_accuracy: 0.6983\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.7001 - val_loss: 0.6422 - val_accuracy: 0.6978\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.6917 - val_loss: 0.6464 - val_accuracy: 0.6956\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6961 - val_loss: 0.6474 - val_accuracy: 0.6911\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6999 - val_loss: 0.6486 - val_accuracy: 0.6894\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.7051 - val_loss: 0.6412 - val_accuracy: 0.6961\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7034 - val_loss: 0.6432 - val_accuracy: 0.7039\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6241 - accuracy: 0.7050 - val_loss: 0.6484 - val_accuracy: 0.6900\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.7042 - val_loss: 0.6442 - val_accuracy: 0.6917\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6207 - accuracy: 0.7083 - val_loss: 0.6421 - val_accuracy: 0.7011\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7015 - val_loss: 0.6437 - val_accuracy: 0.7006\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7010 - val_loss: 0.6396 - val_accuracy: 0.6917\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7062 - val_loss: 0.6427 - val_accuracy: 0.6900\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7047 - val_loss: 0.6471 - val_accuracy: 0.6872\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.7047 - val_loss: 0.6409 - val_accuracy: 0.6850\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.7062 - val_loss: 0.6433 - val_accuracy: 0.6911\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7059 - val_loss: 0.6444 - val_accuracy: 0.6950\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.7077 - val_loss: 0.6507 - val_accuracy: 0.6917\n",
            "Epoch 57/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6184 - accuracy: 0.7076 - val_loss: 0.6451 - val_accuracy: 0.6928\n",
            "Epoch 58/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7141 - val_loss: 0.6470 - val_accuracy: 0.6878\n",
            "Epoch 59/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.7094 - val_loss: 0.6443 - val_accuracy: 0.6956\n",
            "Epoch 60/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.7131 - val_loss: 0.6414 - val_accuracy: 0.6906\n",
            "Epoch 61/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7099 - val_loss: 0.6432 - val_accuracy: 0.6850\n",
            "Epoch 62/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7163 - val_loss: 0.6402 - val_accuracy: 0.6906\n",
            "Epoch 63/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7092 - val_loss: 0.6557 - val_accuracy: 0.6922\n",
            "Epoch 64/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7099 - val_loss: 0.6476 - val_accuracy: 0.6750\n",
            "Epoch 65/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.7064 - val_loss: 0.6482 - val_accuracy: 0.6956\n",
            "Epoch 66/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.7115 - val_loss: 0.6397 - val_accuracy: 0.6956\n",
            "Epoch 67/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7123 - val_loss: 0.6463 - val_accuracy: 0.6967\n",
            "Epoch 68/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.7160 - val_loss: 0.6537 - val_accuracy: 0.6894\n",
            "Epoch 69/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6158 - accuracy: 0.7098 - val_loss: 0.6434 - val_accuracy: 0.6906\n",
            "Epoch 70/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.7116 - val_loss: 0.6412 - val_accuracy: 0.6961\n",
            "Epoch 71/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.7174 - val_loss: 0.6436 - val_accuracy: 0.6928\n",
            "Epoch 72/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.7112 - val_loss: 0.6478 - val_accuracy: 0.6961\n",
            "Epoch 73/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.7042 - val_loss: 0.6464 - val_accuracy: 0.6911\n",
            "Epoch 74/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7186 - val_loss: 0.6402 - val_accuracy: 0.7022\n",
            "Epoch 75/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.7143 - val_loss: 0.6409 - val_accuracy: 0.6950\n",
            "Epoch 76/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7143 - val_loss: 0.6474 - val_accuracy: 0.6861\n",
            "Epoch 77/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7116 - val_loss: 0.6440 - val_accuracy: 0.7017\n",
            "Epoch 78/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.7163 - val_loss: 0.6424 - val_accuracy: 0.6928\n",
            "Epoch 79/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7126 - val_loss: 0.6456 - val_accuracy: 0.6978\n",
            "Epoch 80/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7156 - val_loss: 0.6455 - val_accuracy: 0.7011\n",
            "Epoch 81/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.7140 - val_loss: 0.6543 - val_accuracy: 0.6911\n",
            "Epoch 82/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.7133 - val_loss: 0.6505 - val_accuracy: 0.6694\n",
            "Epoch 83/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.7125 - val_loss: 0.6433 - val_accuracy: 0.7000\n",
            "Epoch 84/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7171 - val_loss: 0.6486 - val_accuracy: 0.6811\n",
            "Epoch 85/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.7155 - val_loss: 0.6509 - val_accuracy: 0.6833\n",
            "Epoch 86/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.7163 - val_loss: 0.6469 - val_accuracy: 0.6928\n",
            "Epoch 87/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.7131 - val_loss: 0.6462 - val_accuracy: 0.6967\n",
            "Epoch 88/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7242 - val_loss: 0.6442 - val_accuracy: 0.6928\n",
            "Epoch 89/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 0.7151 - val_loss: 0.6483 - val_accuracy: 0.6939\n",
            "Epoch 90/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.7164 - val_loss: 0.6532 - val_accuracy: 0.6794\n",
            "Epoch 91/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.7126 - val_loss: 0.6435 - val_accuracy: 0.7000\n",
            "Epoch 92/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6067 - accuracy: 0.7177 - val_loss: 0.6443 - val_accuracy: 0.6950\n",
            "Epoch 93/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.7171 - val_loss: 0.6537 - val_accuracy: 0.6961\n",
            "Epoch 94/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.7182 - val_loss: 0.6470 - val_accuracy: 0.6872\n",
            "Epoch 95/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7170 - val_loss: 0.6505 - val_accuracy: 0.6972\n",
            "Epoch 96/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7155 - val_loss: 0.6646 - val_accuracy: 0.6833\n",
            "Epoch 97/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.7138 - val_loss: 0.6446 - val_accuracy: 0.6861\n",
            "Epoch 98/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.7229 - val_loss: 0.6440 - val_accuracy: 0.6861\n",
            "Epoch 99/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6047 - accuracy: 0.7217 - val_loss: 0.6439 - val_accuracy: 0.6928\n",
            "Epoch 100/200\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7218 - val_loss: 0.6503 - val_accuracy: 0.6950\n",
            "Epoch 101/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7230 - val_loss: 0.6516 - val_accuracy: 0.6906\n",
            "Epoch 102/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5988 - accuracy: 0.7271 - val_loss: 0.6452 - val_accuracy: 0.6967\n",
            "Epoch 103/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.7238 - val_loss: 0.6442 - val_accuracy: 0.7061\n",
            "Epoch 104/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7318 - val_loss: 0.6493 - val_accuracy: 0.6983\n",
            "Epoch 105/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.7260 - val_loss: 0.6490 - val_accuracy: 0.7011\n",
            "Epoch 106/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.7256 - val_loss: 0.6473 - val_accuracy: 0.6911\n",
            "Epoch 107/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.7197 - val_loss: 0.6482 - val_accuracy: 0.7006\n",
            "Epoch 108/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.7193 - val_loss: 0.6502 - val_accuracy: 0.6906\n",
            "Epoch 109/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7300 - val_loss: 0.6475 - val_accuracy: 0.6878\n",
            "Epoch 110/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6029 - accuracy: 0.7168 - val_loss: 0.6471 - val_accuracy: 0.6878\n",
            "Epoch 111/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.7265 - val_loss: 0.6548 - val_accuracy: 0.6939\n",
            "Epoch 112/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.7183 - val_loss: 0.6476 - val_accuracy: 0.6783\n",
            "Epoch 113/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6020 - accuracy: 0.7247 - val_loss: 0.6609 - val_accuracy: 0.6889\n",
            "Epoch 114/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7177 - val_loss: 0.6486 - val_accuracy: 0.6806\n",
            "Epoch 115/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.7212 - val_loss: 0.6488 - val_accuracy: 0.6939\n",
            "Epoch 116/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6029 - accuracy: 0.7279 - val_loss: 0.6612 - val_accuracy: 0.6939\n",
            "Epoch 117/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6020 - accuracy: 0.7268 - val_loss: 0.6443 - val_accuracy: 0.6906\n",
            "Epoch 118/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.7274 - val_loss: 0.6496 - val_accuracy: 0.6900\n",
            "Epoch 119/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.7306 - val_loss: 0.6565 - val_accuracy: 0.6878\n",
            "Epoch 120/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.7272 - val_loss: 0.6493 - val_accuracy: 0.6933\n",
            "Epoch 121/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.7265 - val_loss: 0.6472 - val_accuracy: 0.6889\n",
            "Epoch 122/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7265 - val_loss: 0.6528 - val_accuracy: 0.6894\n",
            "Epoch 123/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7238 - val_loss: 0.6635 - val_accuracy: 0.6856\n",
            "Epoch 124/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.7166 - val_loss: 0.6460 - val_accuracy: 0.6889\n",
            "Epoch 125/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6036 - accuracy: 0.7250 - val_loss: 0.6505 - val_accuracy: 0.6956\n",
            "Epoch 126/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7275 - val_loss: 0.6456 - val_accuracy: 0.6844\n",
            "Epoch 127/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7321 - val_loss: 0.6494 - val_accuracy: 0.6917\n",
            "Epoch 128/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7362 - val_loss: 0.6466 - val_accuracy: 0.6928\n",
            "Epoch 129/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6011 - accuracy: 0.7229 - val_loss: 0.6487 - val_accuracy: 0.6872\n",
            "Epoch 130/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.7259 - val_loss: 0.6501 - val_accuracy: 0.6906\n",
            "Epoch 131/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7295 - val_loss: 0.6472 - val_accuracy: 0.6933\n",
            "Epoch 132/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5916 - accuracy: 0.7348 - val_loss: 0.6566 - val_accuracy: 0.6944\n",
            "Epoch 133/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.7225 - val_loss: 0.6556 - val_accuracy: 0.6756\n",
            "Epoch 134/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.7200 - val_loss: 0.6533 - val_accuracy: 0.6928\n",
            "Epoch 135/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.7318 - val_loss: 0.6471 - val_accuracy: 0.6883\n",
            "Epoch 136/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.7352 - val_loss: 0.6529 - val_accuracy: 0.6889\n",
            "Epoch 137/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.7365 - val_loss: 0.6484 - val_accuracy: 0.6944\n",
            "Epoch 138/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7266 - val_loss: 0.6515 - val_accuracy: 0.6922\n",
            "Epoch 139/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7332 - val_loss: 0.6507 - val_accuracy: 0.6922\n",
            "Epoch 140/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.7399 - val_loss: 0.6515 - val_accuracy: 0.6872\n",
            "Epoch 141/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.7343 - val_loss: 0.6544 - val_accuracy: 0.7044\n",
            "Epoch 142/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7355 - val_loss: 0.6489 - val_accuracy: 0.6933\n",
            "Epoch 143/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7374 - val_loss: 0.6507 - val_accuracy: 0.6844\n",
            "Epoch 144/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.7332 - val_loss: 0.6557 - val_accuracy: 0.6906\n",
            "Epoch 145/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.7348 - val_loss: 0.6528 - val_accuracy: 0.6856\n",
            "Epoch 146/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.7310 - val_loss: 0.6501 - val_accuracy: 0.6889\n",
            "Epoch 147/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.7339 - val_loss: 0.6477 - val_accuracy: 0.6928\n",
            "Epoch 148/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5933 - accuracy: 0.7322 - val_loss: 0.6630 - val_accuracy: 0.6906\n",
            "Epoch 149/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.7424 - val_loss: 0.6572 - val_accuracy: 0.6922\n",
            "Epoch 150/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.7358 - val_loss: 0.6518 - val_accuracy: 0.6900\n",
            "Epoch 151/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.7333 - val_loss: 0.6518 - val_accuracy: 0.6844\n",
            "Epoch 152/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.7374 - val_loss: 0.6555 - val_accuracy: 0.6889\n",
            "Epoch 153/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7363 - val_loss: 0.6497 - val_accuracy: 0.6928\n",
            "Epoch 154/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7342 - val_loss: 0.6513 - val_accuracy: 0.6922\n",
            "Epoch 155/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.7335 - val_loss: 0.6598 - val_accuracy: 0.6956\n",
            "Epoch 156/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.7381 - val_loss: 0.6519 - val_accuracy: 0.6928\n",
            "Epoch 157/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.7319 - val_loss: 0.6540 - val_accuracy: 0.6906\n",
            "Epoch 158/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7308 - val_loss: 0.6653 - val_accuracy: 0.6750\n",
            "Epoch 159/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7307 - val_loss: 0.6595 - val_accuracy: 0.6944\n",
            "Epoch 160/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5862 - accuracy: 0.7380 - val_loss: 0.6520 - val_accuracy: 0.6856\n",
            "Epoch 161/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.7364 - val_loss: 0.6538 - val_accuracy: 0.6906\n",
            "Epoch 162/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.7398 - val_loss: 0.6594 - val_accuracy: 0.6789\n",
            "Epoch 163/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7381 - val_loss: 0.6565 - val_accuracy: 0.6956\n",
            "Epoch 164/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7401 - val_loss: 0.6539 - val_accuracy: 0.6861\n",
            "Epoch 165/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7401 - val_loss: 0.6585 - val_accuracy: 0.6900\n",
            "Epoch 166/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7414 - val_loss: 0.6567 - val_accuracy: 0.6844\n",
            "Epoch 167/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7331 - val_loss: 0.6505 - val_accuracy: 0.6944\n",
            "Epoch 168/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7429 - val_loss: 0.6573 - val_accuracy: 0.6906\n",
            "Epoch 169/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.7427 - val_loss: 0.6552 - val_accuracy: 0.6956\n",
            "Epoch 170/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.7366 - val_loss: 0.6595 - val_accuracy: 0.6778\n",
            "Epoch 171/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.7385 - val_loss: 0.6691 - val_accuracy: 0.6894\n",
            "Epoch 172/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7346 - val_loss: 0.6535 - val_accuracy: 0.6878\n",
            "Epoch 173/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5856 - accuracy: 0.7423 - val_loss: 0.6569 - val_accuracy: 0.6833\n",
            "Epoch 174/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.7310 - val_loss: 0.6571 - val_accuracy: 0.6839\n",
            "Epoch 175/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7450 - val_loss: 0.6561 - val_accuracy: 0.6850\n",
            "Epoch 176/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.7423 - val_loss: 0.6573 - val_accuracy: 0.6883\n",
            "Epoch 177/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.7423 - val_loss: 0.6682 - val_accuracy: 0.6733\n",
            "Epoch 178/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7304 - val_loss: 0.6532 - val_accuracy: 0.6839\n",
            "Epoch 179/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.7331 - val_loss: 0.6547 - val_accuracy: 0.6867\n",
            "Epoch 180/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.7426 - val_loss: 0.6572 - val_accuracy: 0.6850\n",
            "Epoch 181/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7362 - val_loss: 0.6549 - val_accuracy: 0.6889\n",
            "Epoch 182/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.7351 - val_loss: 0.6572 - val_accuracy: 0.6906\n",
            "Epoch 183/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7418 - val_loss: 0.6572 - val_accuracy: 0.6750\n",
            "Epoch 184/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.7419 - val_loss: 0.6534 - val_accuracy: 0.6872\n",
            "Epoch 185/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.7375 - val_loss: 0.6638 - val_accuracy: 0.6850\n",
            "Epoch 186/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.7330 - val_loss: 0.6657 - val_accuracy: 0.6894\n",
            "Epoch 187/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7429 - val_loss: 0.6560 - val_accuracy: 0.6833\n",
            "Epoch 188/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7450 - val_loss: 0.6579 - val_accuracy: 0.6900\n",
            "Epoch 189/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7441 - val_loss: 0.6606 - val_accuracy: 0.6900\n",
            "Epoch 190/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7422 - val_loss: 0.6552 - val_accuracy: 0.6794\n",
            "Epoch 191/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7489 - val_loss: 0.6648 - val_accuracy: 0.6833\n",
            "Epoch 192/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7393 - val_loss: 0.6611 - val_accuracy: 0.6872\n",
            "Epoch 193/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.7430 - val_loss: 0.6566 - val_accuracy: 0.6756\n",
            "Epoch 194/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5862 - accuracy: 0.7390 - val_loss: 0.6575 - val_accuracy: 0.6833\n",
            "Epoch 195/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7481 - val_loss: 0.6550 - val_accuracy: 0.6900\n",
            "Epoch 196/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7427 - val_loss: 0.6556 - val_accuracy: 0.6872\n",
            "Epoch 197/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.7420 - val_loss: 0.6558 - val_accuracy: 0.6850\n",
            "Epoch 198/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7514 - val_loss: 0.6692 - val_accuracy: 0.6772\n",
            "Epoch 199/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.7389 - val_loss: 0.6621 - val_accuracy: 0.6822\n",
            "Epoch 200/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5834 - accuracy: 0.7430 - val_loss: 0.6639 - val_accuracy: 0.6839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH_dALQzA7t0"
      },
      "source": [
        "### Some of the trials\n",
        "* **l1= 0.01, l2= 0.000001** : loss: 1.6827 - accuracy: 0.5303 - val_loss: 1.6733 - val_accuracy: 0.5422 ,   ***accuracy gap = 1.19%***\n",
        "\n",
        "\n",
        "* **l1= 0.0000001, l2= 0.01** : loss: 0.5671 - accuracy: 0.7576 - val_loss: 0.6431 - val_accuracy: 0.7028 ,   ***accuracy gap = 5.48%***     \n",
        "\n",
        "\n",
        "* **l1= 0.000001, l2= 0.01** : loss: 0.5650 - accuracy: 0.7553 - val_loss: 0.6367 - val_accuracy: 0.7028 ,   ***accuracy gap = 5.25%***\n",
        "\n",
        "* **l1= 0.00006, l2= 0.01** : loss: 0.5855 - accuracy: 0.7321 - val_loss: 0.6260 - val_accuracy: 0.7028 ,   ***accuracy gap = 2.93%***\n",
        "\n",
        "* **l1= 0.000075, l2= 0.01** : loss: 0.6075 - accuracy: 0.7171 - val_loss: 0.6321 - val_accuracy: 0.7006 ,   ***accuracy gap = 1.65%***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol-q_8HBE0Ev"
      },
      "source": [
        "The first model was the best one that minimized overfitting (with 1.19% accuracy gap). However, the last model minimized overfitting too with an acceptable gap percentage (1.65%) but better training and validation accuracies than the first one, so it is better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA9PXP8foVEX"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "s09n2jVa08N_",
        "outputId": "62984d9f-a2ca-4261-fccf-3515654fdec8"
      },
      "source": [
        "plotter(regularizer_histories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgTbOxxroEhj"
      },
      "source": [
        "## Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypwsYdVSLofz"
      },
      "source": [
        "regularizer_histories = {} # new dictionary to store regularized model histories\n",
        "#regularizer_histories['dropout'] = model_histories['dropout']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR2bgUHooENS",
        "outputId": "759319ad-07f6-42d0-ae03-677350fec5f9"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "c = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0,\n",
        "    patience=40,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "regularizer_histories['dropout_earlyStopping'] = compile_and_fit(dropout_model, max_epochs = EPOCHS, callback = c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 512)               14848     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 803,329\n",
            "Trainable params: 803,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 0.3168 - accuracy: 0.8600 - val_loss: 0.7297 - val_accuracy: 0.6778\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8611 - val_loss: 0.7133 - val_accuracy: 0.6694\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8649 - val_loss: 0.7435 - val_accuracy: 0.6706\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8595 - val_loss: 0.7194 - val_accuracy: 0.6822\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.8643 - val_loss: 0.7418 - val_accuracy: 0.6739\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8637 - val_loss: 0.7258 - val_accuracy: 0.6778\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8635 - val_loss: 0.7295 - val_accuracy: 0.6717\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8665 - val_loss: 0.7281 - val_accuracy: 0.6756\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8706 - val_loss: 0.7507 - val_accuracy: 0.6728\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8702 - val_loss: 0.7207 - val_accuracy: 0.6794\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8662 - val_loss: 0.7244 - val_accuracy: 0.6778\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3143 - accuracy: 0.8643 - val_loss: 0.7387 - val_accuracy: 0.6800\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3048 - accuracy: 0.8708 - val_loss: 0.7168 - val_accuracy: 0.6733\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8635 - val_loss: 0.7138 - val_accuracy: 0.6756\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8616 - val_loss: 0.7300 - val_accuracy: 0.6744\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8651 - val_loss: 0.7285 - val_accuracy: 0.6750\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8702 - val_loss: 0.7141 - val_accuracy: 0.6711\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8712 - val_loss: 0.7348 - val_accuracy: 0.6783\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8705 - val_loss: 0.7380 - val_accuracy: 0.6811\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8718 - val_loss: 0.7508 - val_accuracy: 0.6806\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8673 - val_loss: 0.7374 - val_accuracy: 0.6811\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8684 - val_loss: 0.7290 - val_accuracy: 0.6722\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.8706 - val_loss: 0.7312 - val_accuracy: 0.6744\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8651 - val_loss: 0.7549 - val_accuracy: 0.6761\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8676 - val_loss: 0.7345 - val_accuracy: 0.6744\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8715 - val_loss: 0.7211 - val_accuracy: 0.6700\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8673 - val_loss: 0.7306 - val_accuracy: 0.6756\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8660 - val_loss: 0.7373 - val_accuracy: 0.6711\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8738 - val_loss: 0.7422 - val_accuracy: 0.6722\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8742 - val_loss: 0.7453 - val_accuracy: 0.6628\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8725 - val_loss: 0.7594 - val_accuracy: 0.6667\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3005 - accuracy: 0.8677 - val_loss: 0.7462 - val_accuracy: 0.6678\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8746 - val_loss: 0.7486 - val_accuracy: 0.6722\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8748 - val_loss: 0.7460 - val_accuracy: 0.6778\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8745 - val_loss: 0.7600 - val_accuracy: 0.6750\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8732 - val_loss: 0.7481 - val_accuracy: 0.6778\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2887 - accuracy: 0.8740 - val_loss: 0.7346 - val_accuracy: 0.6783\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8742 - val_loss: 0.7389 - val_accuracy: 0.6722\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8738 - val_loss: 0.7478 - val_accuracy: 0.6728\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.8780 - val_loss: 0.7499 - val_accuracy: 0.6728\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8740 - val_loss: 0.7715 - val_accuracy: 0.6661\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8768 - val_loss: 0.7406 - val_accuracy: 0.6717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0NizvoMGAG1"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8elLcVGAHA"
      },
      "source": [
        "plotter(regularizer_histories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drl9_1Bm9rSU"
      },
      "source": [
        "## Bonus Questions\n",
        "\n",
        "1. [0.5 pt] In the code above, we used `kernel_regularizer`. What is the difference between `kernel_regularizer`, `bias_regularizer`, and`activity_regularizer` in Keras?\n",
        "> * kernel_regularizer: reduces the weights (W)\n",
        "> * bias_regularizer: reduces the bias (b)\n",
        "> * activity_regularizer: reduces both the weights and bias (Wx+b)\n",
        "\n",
        "1. [0.5 pt] When should you use each?\n",
        "> bias regularizer: if I want the output to pass through the origin, activity regularizer: if I want the output to be small, kernel regularizer: If I have no prior knowledge on the distribution of the model.\n",
        "1. [1 pt] What is the difference between the effect of L1 regularization and that of L2 regularization? Explain in light of the figure below.\n",
        "<center><img src=\"https://miro.medium.com/max/602/0*_pKBpbrub8v6np5x.png\" width=\"300px\"></center>\n",
        "\n",
        "    > L1 regularizer can make some weights = 0 as it minimizes the absolute values of the weights, so it is can be used for feature extraction. While L2 does not do so as it minimizes the sum of squared values of the weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbr24DTnvCj8"
      },
      "source": [
        "# References\n",
        "* https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\n",
        "* https://github.com/stwunsch/fermilab_keras_workshop\n",
        "* https://www.tensorflow.org/tutorials/keras/overfit_and_underfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdnDKdc2JNnU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}